# Guardar conversaciones
            with open(self.archivos['conversaciones'], 'w', encoding='utf-8') as f:
                json.dump(self.conversaciones, f, indent=2, ensure_ascii=False)
            
            # Guardar configuraci√≥n
            config_data = {
                'nombre': self.nombre,
                'version': self.version,
                'vocab_size': self.vocab_size,
                'embedding_dim': self.embedding_dim,
                'hidden_dim': self.hidden_dim,
                'auto_entrenamiento': self.auto_entrenamiento_activo,
                'auto_mejora': self.auto_mejora_activa
            }
            
            with open(self.archivos['config'], 'w', encoding='utf-8') as f:
                json.dump(config_data, f, indent=2)
            
            # Guardar datos de auto-aprendizaje
            self._guardar_datos_auto_aprendizaje()
            
            # Guardar memoria permanente - NUNCA SE OLVIDA
            self._guardar_memoria_permanente()
            
            logger.info("üíæ Modelo guardado exitosamente")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error guardando modelo: {e}")
            return False
    
    def mostrar_estadisticas(self):
        """Muestra estad√≠sticas detalladas del modelo"""
        self.interfaz.imprimir_banner("ESTAD√çSTICAS DEL MODELO", Colors.CYAN)
        
        # Informaci√≥n b√°sica
        self.interfaz.imprimir_seccion("Informaci√≥n General")
        self.interfaz.imprimir_estadistica("Nombre", self.nombre)
        self.interfaz.imprimir_estadistica("Versi√≥n", self.version)
        self.interfaz.imprimir_estadistica("Vocabulario", f"{len(self.vocabulario):,} palabras")
        self.interfaz.imprimir_estadistica("Conversaciones", f"{len(self.conversaciones):,}")
        
        # Memoria permanente
        self.interfaz.imprimir_seccion("Memoria Permanente")
        self.interfaz.imprimir_estadistica("Experiencias importantes", len(self.memoria_permanente['experiencias_importantes']))
        self.interfaz.imprimir_estadistica("Lecciones aprendidas", len(self.memoria_permanente['lecciones_aprendidas']))
        self.interfaz.imprimir_estadistica("Patrones detectados", len(self.memoria_permanente['patrones_detectados']))
        self.interfaz.imprimir_estadistica("Mejoras realizadas", len(self.memoria_permanente['mejoras_realizadas']))
        
        # Arquitectura
        self.interfaz.imprimir_seccion("Arquitectura")
        self.interfaz.imprimir_estadistica("Embedding", f"{self.vocab_size:,} x {self.embedding_dim}")
        self.interfaz.imprimir_estadistica("Hidden Layer", f"{self.embedding_dim} x {self.hidden_dim}")
        self.interfaz.imprimir_estadistica("Output Layer", f"{self.hidden_dim} x {self.vocab_size:,}")
        
        # M√©tricas de rendimiento
        if self.metricas_rendimiento['tiempo_respuesta']:
            tiempos = self.metricas_rendimiento['tiempo_respuesta']
            self.interfaz.imprimir_seccion("Rendimiento")
            self.interfaz.imprimir_estadistica("Tiempo promedio", f"{np.mean(tiempos):.3f}s")
            self.interfaz.imprimir_estadistica("Tiempo m√≠nimo", f"{np.min(tiempos):.3f}s")
            self.interfaz.imprimir_estadistica("Tiempo m√°ximo", f"{np.max(tiempos):.3f}s")
        
        # Estado de funcionalidades
        self.interfaz.imprimir_seccion("Configuraci√≥n")
        auto_train = "üü¢ ACTIVO" if self.auto_entrenamiento_activo else "üî¥ INACTIVO"
        auto_improve = "üü¢ ACTIVA" if self.auto_mejora_activa else "üî¥ INACTIVA"
        auto_evolve = "üü¢ ACTIVA" if self.auto_evolucion_activa else "üî¥ INACTIVA"
        auto_question = "üü¢ ACTIVO" if self.auto_cuestionamiento_activo else "üî¥ INACTIVO"
        
        self.interfaz.imprimir_estadistica("Auto-entrenamiento", auto_train)
        self.interfaz.imprimir_estadistica("Auto-mejora", auto_improve)
        self.interfaz.imprimir_estadistica("Auto-evoluci√≥n", auto_evolve)
        self.interfaz.imprimir_estadistica("Auto-cuestionamiento", auto_question)
        self.interfaz.imprimir_estadistica("Learning Rate", f"{self.learning_rate:.6f}")
        
        # Estad√≠sticas de auto-aprendizaje
        if self.sesiones_auto_aprendizaje:
            self.interfaz.imprimir_seccion("Auto-Aprendizaje")
            self.interfaz.imprimir_estadistica("Sesiones realizadas", len(self.sesiones_auto_aprendizaje))
            self.interfaz.imprimir_estadistica("Versiones creadas", len(self.versiones_anteriores))
            
            # √öltima sesi√≥n
            ultima_sesion = self.sesiones_auto_aprendizaje[-1]
            if 'preguntas_realizadas' in ultima_sesion:
                preguntas = len(ultima_sesion['preguntas_realizadas'])
                mejoras = len(ultima_sesion.get('mejoras_identificadas', []))
                self.interfaz.imprimir_estadistica("√öltima sesi√≥n - Preguntas", preguntas)
                self.interfaz.imprimir_estadistica("√öltima sesi√≥n - Mejoras", mejoras)
    
    def mostrar_historial_conversacion(self, ultimas: int = 10):
        """Muestra el historial de conversaciones"""
        self.interfaz.imprimir_banner("HISTORIAL DE CONVERSACIONES", Colors.PURPLE)
        
        if not self.conversaciones:
            print(f"{Colors.YELLOW}üì≠ No hay conversaciones registradas{Colors.END}")
            return
        
        conversaciones_mostrar = self.conversaciones[-ultimas:] if len(self.conversaciones) > ultimas else self.conversaciones
        
        for i, conv in enumerate(conversaciones_mostrar, 1):
            timestamp = conv['timestamp'][:19].replace('T', ' ')
            tiempo_resp = conv.get('tiempo_respuesta', 0)
            
            print(f"\n{Colors.CYAN}{i}. {timestamp} (‚è±Ô∏è {tiempo_resp:.3f}s){Colors.END}")
            print(f"{Colors.GREEN}üë§ Usuario: {conv['entrada']}{Colors.END}")
            print(f"{Colors.BLUE}ü§ñ Modelo: {conv['respuesta']}{Colors.END}")
    
    def crear_backup(self) -> bool:
        """Crea un backup completo del modelo"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_dir = f"{self.archivos['backups']}/backup_{timestamp}"
            os.makedirs(backup_dir, exist_ok=True)
            
            # Copiar archivos principales
            archivos_backup = ['pesos', 'vocabulario', 'conversaciones', 'config', 'auto_aprendizaje', 'memoria_permanente']
            for archivo in archivos_backup:
                if os.path.exists(self.archivos[archivo]):
                    shutil.copy2(self.archivos[archivo], f"{backup_dir}/{os.path.basename(self.archivos[archivo])}")
            
            logger.info(f"üíæ Backup creado: {backup_dir}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error creando backup: {e}")
            return False
    
    def entrenar_interactivo(self):
        """Entrenamiento interactivo mejorado"""
        self.interfaz.imprimir_banner("MODO ENTRENAMIENTO INTERACTIVO", Colors.YELLOW)
        
        print(f"{Colors.CYAN}üìñ Instrucciones:{Colors.END}")
        print("‚Ä¢ Escribe frases para entrenar el modelo")
        print("‚Ä¢ Usa '/save' para guardar progreso")
        print("‚Ä¢ Usa '/quit' para salir del entrenamiento")
        print("‚Ä¢ El modelo aprender√° de cada entrada")
        
        iteracion = 0
        while True:
            try:
                entrada = self.interfaz.solicitar_entrada(f"\n[Entrenamiento {iteracion+1}] üìù Entrada: ")
                
                if entrada == '/quit':
                    break
                elif entrada == '/save':
                    if self.guardar_modelo():
                        print(f"{Colors.GREEN}‚úÖ Progreso guardado{Colors.END}")
                    continue
                elif not entrada:
                    continue
                
                # Simular entrenamiento (en un modelo real, aqu√≠ ir√≠a el algoritmo de entrenamiento)
                tiempo_inicio = time.time()
                
                # Tokenizar y procesar
                tokens = self._tokenizar_simple(entrada)
                if tokens:
                    # Forward pass simulado
                    _ = self._forward_pass_simple(tokens)
                    
                    tiempo_entrenamiento = time.time() - tiempo_inicio
                    error_simulado = random.uniform(0.5, 2.0) * (0.95 ** iteracion)  # Error decreciente
                    
                    print(f"{Colors.GREEN}‚úÖ Iteraci√≥n {iteracion+1} completada{Colors.END}")
                    print(f"   ‚è±Ô∏è Tiempo: {tiempo_entrenamiento:.4f}s")
                    print(f"   üìä Error simulado: {error_simulado:.6f}")
                    
                    self.historial_error.append(error_simulado)
                    
                    # Guardar en memoria permanente
                    self.memoria_permanente['experiencias_importantes'].append({
                        'tipo': 'entrenamiento',
                        'contenido': entrada,
                        'error': error_simulado,
                        'timestamp': datetime.now().isoformat()
                    })
                    
                    iteracion += 1
                
            except KeyboardInterrupt:
                print(f"\n{Colors.YELLOW}‚ö†Ô∏è Entrenamiento interrumpido{Colors.END}")
                break
        
        print(f"\n{Colors.CYAN}üìà Entrenamiento completado: {iteracion} iteraciones{Colors.END}")
        self._guardar_memoria_permanente()
    
    def _tokenizar_simple(self, texto: str) -> List[int]:
        """Tokenizaci√≥n simple para entrenamiento"""
        palabras = texto.lower().split()
        tokens = []
        
        for palabra in palabras:
            if palabra not in self.vocabulario:
                if self.contador_vocab < self.vocab_size:
                    self.vocabulario[palabra] = self.contador_vocab
                    self.vocabulario_inverso[self.contador_vocab] = palabra
                    self.contador_vocab += 1
                else:
                    palabra = "<UNK>"
            
            tokens.append(self.vocabulario[palabra])
        
        return tokens
    
    def _forward_pass_simple(self, tokens: List[int]) -> np.ndarray:
        """Forward pass simplificado"""
        if not tokens:
            return np.zeros((1, self.vocab_size))
        
        # Embedding promedio
        embeddings = []
        for token in tokens:
            if token < len(self.W_embedding):
                embeddings.append(self.W_embedding[token])
            else:
                embeddings.append(self.W_embedding[1])  # UNK token
        
        if embeddings:
            input_vec = np.mean(embeddings, axis=0).reshape(1, -1)
            hidden = np.maximum(0, np.dot(input_vec, self.W_hidden) + self.b_hidden)
            output = np.dot(hidden, self.W_output) + self.b_output
            return self._softmax(output)
        
        return np.zeros((1, self.vocab_size))
    
    def _softmax(self, x: np.ndarray) -> np.ndarray:
        """Funci√≥n softmax estable"""
        exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=-1, keepdims=True)
    
    def configurar_modelo(self):
        """Configuraci√≥n interactiva del modelo"""
        self.interfaz.imprimir_banner("CONFIGURACI√ìN DEL MODELO", Colors.PURPLE)
        
        opciones = {
            '1': 'Cambiar learning rate',
            '2': 'Toggle auto-entrenamiento',
            '3': 'Toggle auto-mejora',
            '4': 'Configurar temperatura de generaci√≥n',
            '5': 'Configurar API key de OpenAI',
            '6': 'Toggle auto-evoluci√≥n',
            '7': 'Toggle auto-cuestionamiento',
            '8': 'Limpiar historial de conversaciones',
            '9': 'Resetear vocabulario',
            '10': 'Ver memoria permanente',
            '11': 'Volver al men√∫ principal'
        }
        
        while True:
            self.interfaz.mostrar_menu(opciones, "OPCIONES DE CONFIGURACI√ìN")
            
            opcion = self.interfaz.solicitar_entrada("\nüîß Selecciona una opci√≥n: ")
            
            if opcion == '1':
                try:
                    nuevo_lr = float(self.interfaz.solicitar_entrada("üìä Nuevo learning rate (actual: {:.6f}): ".format(self.learning_rate)))
                    if 0.0001 <= nuevo_lr <= 1.0:
                        self.learning_rate = nuevo_lr
                        print(f"{Colors.GREEN}‚úÖ Learning rate actualizado a {nuevo_lr:.6f}{Colors.END}")
                    else:
                        print(f"{Colors.RED}‚ùå Learning rate debe estar entre 0.0001 y 1.0{Colors.END}")
                except ValueError:
                    print(f"{Colors.RED}‚ùå Valor inv√°lido{Colors.END}")
            
            elif opcion == '2':
                self.auto_entrenamiento_activo = not self.auto_entrenamiento_activo
                estado = "üü¢ ACTIVADO" if self.auto_entrenamiento_activo else "üî¥ DESACTIVADO"
                print(f"{Colors.GREEN}üîÑ Auto-entrenamiento: {estado}{Colors.END}")
            
            elif opcion == '3':
                self.auto_mejora_activa = not self.auto_mejora_activa
                estado = "üü¢ ACTIVADA" if self.auto_mejora_activa else "üî¥ DESACTIVADA"
                print(f"{Colors.GREEN}üöÄ Auto-mejora: {estado}{Colors.END}")
            
            elif opcion == '4':
                try:
                    nueva_temp = float(self.interfaz.solicitar_entrada("üå°Ô∏è Nueva temperatura (actual: {:.2f}): ".format(self.config.temperature)))
                    if 0.1 <= nueva_temp <= 2.0:
                        self.config.temperature = nueva_temp
                        print(f"{Colors.GREEN}‚úÖ Temperatura actualizada a {nueva_temp:.2f}{Colors.END}")
                    else:
                        print(f"{Colors.RED}‚ùå Temperatura debe estar entre 0.1 y 2.0{Colors.END}")
                except ValueError:
                    print(f"{Colors.RED}‚ùå Valor inv√°lido{Colors.END}")
            
            elif opcion == '5':
                nueva_key = self.interfaz.solicitar_entrada("üîë Nueva API key de OpenAI (deja vac√≠o para no cambiar): ")
                if nueva_key:
                    self.config.openai_api_key = nueva_key
                    self.juez_openai = JuezOpenAI(nueva_key)
                    print(f"{Colors.GREEN}‚úÖ API key actualizada{Colors.END}")
            
            elif opcion == '6':
                self.auto_evolucion_activa = not self.auto_evolucion_activa
                estado = "üü¢ ACTIVADA" if self.auto_evolucion_activa else "üî¥ DESACTIVADA"
                print(f"{Colors.GREEN}üß¨ Auto-evoluci√≥n: {estado}{Colors.END}")
            
            elif opcion == '7':
                self.auto_cuestionamiento_activo = not self.auto_cuestionamiento_activo
                estado = "üü¢ ACTIVADO" if self.auto_cuestionamiento_activo else "üî¥ INACTIVO"
                print(f"{Colors.GREEN}ü§î Auto-cuestionamiento: {estado}{Colors.END}")
            
            elif opcion == '8':
                confirmacion = self.interfaz.solicitar_entrada("‚ö†Ô∏è ¬øConfirmas limpiar historial? (s/N): ")
                if confirmacion.lower() == 's':
                    self.conversaciones.clear()
                    self.metricas_rendimiento = {k: [] for k in self.metricas_rendimiento.keys()}
                    print(f"{Colors.GREEN}‚úÖ Historial limpiado{Colors.END}")
            
            elif opcion == '9':
                confirmacion = self.interfaz.solicitar_entrada("‚ö†Ô∏è ¬øConfirmas resetear vocabulario? (s/N): ")
                if confirmacion.lower() == 's':
                    self.vocabulario = {"<PAD>": 0, "<UNK>": 1, "<START>": 2, "<END>": 3, "<MASK>": 4}
                    self.vocabulario_inverso = {0: "<PAD>", 1: "<UNK>", 2: "<START>", 3: "<END>", 4: "<MASK>"}
                    self.contador_vocab = 5
                    print(f"{Colors.GREEN}‚úÖ Vocabulario reseteado{Colors.END}")
            
            elif opcion == '10':
                self._mostrar_memoria_permanente()
            
            elif opcion == '11':
                break
            
            else:
                print(f"{Colors.RED}‚ùå Opci√≥n inv√°lida{Colors.END}")
    
    def _mostrar_memoria_permanente(self):
        """Muestra el contenido de la memoria permanente"""
        self.interfaz.imprimir_banner("MEMORIA PERMANENTE", Colors.PURPLE)
        
        for categoria, items in self.memoria_permanente.items():
            self.interfaz.imprimir_seccion(f"{categoria.replace('_', ' ').title()}")
            
            if items:
                for i, item in enumerate(items[-5:], 1):  # Mostrar √∫ltimos 5
                    timestamp = item.get('timestamp', 'Sin fecha')[:19].replace('T', ' ')
                    tipo = item.get('tipo', 'General')
                    contenido = str(item.get('contenido', item.get('pregunta', 'Sin contenido')))[:100] + "..."
                    
                    print(f"   {i}. [{timestamp}] {tipo}: {contenido}")
            else:
                print(f"   No hay elementos en esta categor√≠a")
    
    def ejecutar_tests(self):
        """Ejecuta tests de validaci√≥n del modelo"""
        self.interfaz.imprimir_banner("EJECUTANDO TESTS DE VALIDACI√ìN", Colors.YELLOW)
        
        tests = [
            ("Test b√°sico de respuesta", self._test_respuesta_basica),
            ("Test de tiempo de respuesta", self._test_tiempo_respuesta),
            ("Test de manejo de entrada vac√≠a", self._test_entrada_vacia),
            ("Test de entrada muy larga", self._test_entrada_larga),
            ("Test de caracteres especiales", self._test_caracteres_especiales),
            ("Test de guardado/carga", self._test_guardado_carga),
            ("Test de memoria permanente", self._test_memoria_permanente)
        ]
        
        resultados = []
        
        for nombre_test, test_func in tests:
            print(f"\nüß™ {nombre_test}...")
            
            try:
                inicio = time.time()
                resultado = test_func()
                tiempo = time.time() - inicio
                
                if resultado:
                    print(f"   {Colors.GREEN}‚úÖ PAS√ì ({tiempo:.3f}s){Colors.END}")
                    resultados.append(True)
                else:
                    print(f"   {Colors.RED}‚ùå FALL√ì ({tiempo:.3f}s){Colors.END}")
                    resultados.append(False)
                    
            except Exception as e:
                print(f"   {Colors.RED}‚ùå ERROR: {e}{Colors.END}")
                resultados.append(False)
        
        # Resumen
        exitosos = sum(resultados)
        total = len(resultados)
        porcentaje = (exitosos / total) * 100
        
        print(f"\nüìä RESUMEN DE TESTS:")
        print(f"   ‚úÖ Exitosos: {exitosos}/{total} ({porcentaje:.1f}%)")
        
        if porcentaje == 100:
            print(f"   {Colors.GREEN}üéâ ¬°Todos los tests pasaron!{Colors.END}")
        elif porcentaje >= 80:
            print(f"   {Colors.YELLOW}‚ö†Ô∏è La mayor√≠a de tests pasaron{Colors.END}")
        else:
            print(f"   {Colors.RED}‚ùå M√∫ltiples tests fallaron{Colors.END}")
        
        # Guardar resultado en memoria permanente
        self.memoria_permanente['experiencias_importantes'].append({
            'tipo': 'test_validacion',
            'exitosos': exitosos,
            'total': total,
            'porcentaje': porcentaje,
            'timestamp': datetime.now().isoformat()
        })
        self._guardar_memoria_permanente()
    
    def _test_respuesta_basica(self) -> bool:
        """Test b√°sico de generaci√≥n de respuesta"""
        respuesta = self.procesar_entrada("Hola, ¬øc√≥mo est√°s?")
        return len(respuesta) > 0 and isinstance(respuesta, str)
    
    def _test_tiempo_respuesta(self) -> bool:
        """Test de tiempo de respuesta razonable"""
        inicio = time.time()
        self.procesar_entrada("Esta es una prueba de tiempo de respuesta")
        tiempo = time.time() - inicio
        return tiempo < 5.0  # Menos de 5 segundos
    
    def _test_entrada_vacia(self) -> bool:
        """Test de manejo de entrada vac√≠a"""
        respuesta = self.procesar_entrada("")
        return len(respuesta) > 0
    
    def _test_entrada_larga(self) -> bool:
        """Test de entrada muy larga"""
        entrada_larga = "Esta es una entrada muy larga " * 50
        respuesta = self.procesar_entrada(entrada_larga)
        return len(respuesta) > 0
    
    def _test_caracteres_especiales(self) -> bool:
        """Test de caracteres especiales"""
        respuesta = self.procesar_entrada("¬øQu√© opinas de los s√≠mbolos @#$%^&*()?")
        return len(respuesta) > 0
    
    def _test_guardado_carga(self) -> bool:
        """Test de guardado y carga"""
        return self.guardar_modelo()
    
    def _test_memoria_permanente(self) -> bool:
        """Test de la memoria permanente"""
        items_antes = len(self.memoria_permanente['experiencias_importantes'])
        
        # Agregar algo a la memoria
        self.memoria_permanente['experiencias_importantes'].append({
            'tipo': 'test',
            'contenido': 'Test de memoria',
            'timestamp': datetime.now().isoformat()
        })
        
        items_despues = len(self.memoria_permanente['experiencias_importantes'])
        return items_despues > items_antes
    
    def modo_interactivo(self):
        """Modo interactivo principal mejorado"""
        self.interfaz.imprimir_banner(f"MODO INTERACTIVO - {self.nombre.upper()}", Colors.GREEN)
        
        print(f"{Colors.CYAN}üí° Comandos disponibles:{Colors.END}")
        print("   /help      - Mostrar ayuda")
        print("   /stats     - Ver estad√≠sticas")
        print("   /config    - Configurar modelo")
        print("   /train     - Modo entrenamiento")
        print("   /test      - Ejecutar tests")
        print("   /history   - Ver historial")
        print("   /save      - Guardar modelo")
        print("   /backup    - Crear backup")
        print("   /self_learn - Iniciar auto-aprendizaje")
        print("   /evolve    - Crear nueva versi√≥n")
        print("   /clone     - Interactuar con versi√≥n anterior")
        print("   /memory    - Ver memoria permanente")
        print("   /gui       - Abrir interfaz gr√°fica")
        print("   /clear     - Limpiar pantalla")
        print("   /quit      - Salir")
        print("-" * 50)
        
        contador_interacciones = 0
        
        while True:
            try:
                entrada = self.interfaz.solicitar_entrada(f"\n[{contador_interacciones+1}] üë§ T√∫: ")
                
                if not entrada:
                    continue
                
                # Procesar comandos
                if entrada.startswith('/'):
                    if entrada == '/quit' or entrada == '/exit':
                        print(f"{Colors.YELLOW}üëã ¬°Hasta luego! Guardando modelo...{Colors.END}")
                        self.guardar_modelo()
                        break
                    
                    elif entrada == '/help':
                        self._mostrar_ayuda_completa()
                    
                    elif entrada == '/stats':
                        self.mostrar_estadisticas()
                    
                    elif entrada == '/config':
                        self.configurar_modelo()
                    
                    elif entrada == '/train':
                        self.entrenar_interactivo()
                    
                    elif entrada == '/test':
                        self.ejecutar_tests()
                    
                    elif entrada == '/history':
                        self.mostrar_historial_conversacion()
                    
                    elif entrada == '/save':
                        if self.guardar_modelo():
                            print(f"{Colors.GREEN}‚úÖ Modelo guardado exitosamente{Colors.END}")
                        else:
                            print(f"{Colors.RED}‚ùå Error guardando modelo{Colors.END}")
                    
                    elif entrada == '/backup':
                        if self.crear_backup():
                            print(f"{Colors.GREEN}‚úÖ Backup creado exitosamente{Colors.END}")
                        else:
                            print(f"{Colors.RED}‚ùå Error creando backup{Colors.END}")
                    
                    elif entrada == '/self_learn':
                        if self.auto_cuestionamiento_activo:
                            duracion = self.interfaz.solicitar_entrada("‚è±Ô∏è Duraci√≥n en minutos (default 5): ")
                            try:
                                duracion = int(duracion) if duracion else 5
                            except ValueError:
                                duracion = 5
                            
                            print(f"{Colors.YELLOW}ü§î Iniciando sesi√≥n de auto-aprendizaje por {duracion} minutos...{Colors.END}")
                            asyncio.run(self.sesion_auto_aprendizaje(duracion))
                        else:
                            print(f"{Colors.RED}‚ùå Auto-cuestionamiento desactivado. Usa /config para activarlo{Colors.END}")
                    
                    elif entrada == '/evolve':
                        if self.auto_evolucion_activa:
                            print(f"{Colors.YELLOW}üß¨ Creando nueva versi√≥n del modelo...{Colors.END}")
                            nueva_version = self.crear_version_de_si_mismo()
                            respuesta = self.interfaz.solicitar_entrada("¬øQuieres cambiar a la nueva versi√≥n? (s/N): ")
                            if respuesta.lower() == 's':
                                print(f"{Colors.GREEN}üîÑ Cambiando a {nueva_version.nombre}...{Colors.END}")
                                print(f"{Colors.CYAN}‚ÑπÔ∏è Reinicia el programa para usar la nueva versi√≥n{Colors.END}")
                        else:
                            print(f"{Colors.RED}‚ùå Auto-evoluci√≥n desactivada. Usa /config para activarla{Colors.END}")
                    
                    elif entrada == '/clone':
                        versiones = self.listar_versiones_disponibles()
                        if versiones:
                            print(f"{Colors.CYAN}üìã Versiones disponibles:{Colors.END}")
                            for i, version in enumerate(versiones, 1):
                                print(f"   {i}. {version}")
                            
                            seleccion = self.interfaz.solicitar_entrada("Selecciona una versi√≥n por n√∫mero: ")
                            try:
                                indice = int(seleccion) - 1
                                if 0 <= indice < len(versiones):
                                    version_seleccionada = versiones[indice]
                                    print(f"{Colors.YELLOW}ü§ù Iniciando di√°logo con {version_seleccionada}...{Colors.END}")
                                    asyncio.run(self.interactuar_con_version_anterior(version_seleccionada))
                                else:
                                    print(f"{Colors.RED}‚ùå Selecci√≥n inv√°lida{Colors.END}")
                            except ValueError:
                                print(f"{Colors.RED}‚ùå Ingresa un n√∫mero v√°lido{Colors.END}")
                        else:
                            print(f"{Colors.YELLOW}üì≠ No hay versiones anteriores disponibles{Colors.END}")
                    
                    elif entrada == '/memory':
                        self._mostrar_memoria_permanente()
                    
                    elif entrada == '/gui':
                        print(f"{Colors.YELLOW}üñ•Ô∏è Abriendo interfaz gr√°fica...{Colors.END}")
                        try:
                            gui = InterfazGrafica(self)
                            gui.ejecutar()
                        except Exception as e:
                            print(f"{Colors.RED}‚ùå Error abriendo GUI: {e}{Colors.END}")
                    
                    elif entrada == '/clear':
                        os.system('cls' if os.name == 'nt' else 'clear')
                        self.interfaz.imprimir_banner(f"MODO INTERACTIVO - {self.nombre.upper()}", Colors.GREEN)
                    
                    else:
                        print(f"{Colors.RED}‚ùå Comando no reconocido. Usa /help para ver comandos disponibles.{Colors.END}")
                    
                    continue
                
                # Procesar conversaci√≥n normal
                inicio_tiempo = time.time()
                respuesta = self.procesar_entrada(entrada)
                tiempo_respuesta = time.time() - inicio_tiempo
                
                print(f"{Colors.BLUE}ü§ñ {self.nombre}: {respuesta}{Colors.END}")
                
                if self.modo_debug:
                    print(f"{Colors.YELLOW}   [Debug: {tiempo_respuesta:.3f}s]{Colors.END}")
                
                contador_interacciones += 1
                
                # Auto-guardar cada 10 interacciones
                if contador_interacciones % 10 == 0:
                    self.guardar_modelo()
                    if self.modo_debug:
                        print(f"{Colors.YELLOW}   [Auto-guardado realizado]{Colors.END}")
                
            except KeyboardInterrupt:
                print(f"\n{Colors.YELLOW}üëã ¬°Hasta luego! Guardando modelo...{Colors.END}")
                self.guardar_modelo()
                break
            except Exception as e:
                logger.error(f"Error en modo interactivo: {e}")
                print(f"{Colors.RED}‚ùå Error inesperado: {e}{Colors.END}")
    
    def _mostrar_ayuda_completa(self):
        """Muestra ayuda completa del sistema"""
        self.interfaz.imprimir_banner("AYUDA COMPLETA", Colors.PURPLE)
        
        secciones = {
            "Comandos B√°sicos": {
                "/help": "Muestra esta ayuda",
                "/quit": "Sale del programa guardando el modelo",
                "/clear": "Limpia la pantalla",
                "/gui": "Abre la interfaz gr√°fica con botones"
            },
            "Informaci√≥n": {
                "/stats": "Muestra estad√≠sticas detalladas del modelo",
                "/history": "Muestra el historial de conversaciones",
                "/config": "Abre el men√∫ de configuraci√≥n",
                "/memory": "Muestra la memoria permanente"
            },
            "Entrenamiento y Tests": {
                "/train": "Inicia el modo de entrenamiento interactivo",
                "/test": "Ejecuta tests de validaci√≥n del modelo"
            },
            "Auto-Aprendizaje y Evoluci√≥n": {
                "/self_learn": "Inicia una sesi√≥n de auto-aprendizaje",
                "/evolve": "Crea una nueva versi√≥n mejorada del modelo",
                "/clone": "Interact√∫a con versiones anteriores del modelo"
            },
            "Gesti√≥n de Datos": {
                "/save": "Guarda el estado actual del modelo",
                "/backup": "Crea un backup completo del modelo"
            }
        }
        
        for seccion, comandos in secciones.items():
            self.interfaz.imprimir_seccion(seccion)
            for comando, descripcion in comandos.items():
                print(f"   {Colors.WHITE}{comando:<12} - {descripcion}{Colors.END}")
        
        print(f"\n{Colors.CYAN}üí° Consejos:{Colors.END}")
        print("‚Ä¢ Haz preguntas naturales para obtener mejores respuestas")
        print("‚Ä¢ El modelo NUNCA OLVIDA - toda informaci√≥n se guarda permanentemente")
        print("‚Ä¢ Usa /gui para una interfaz m√°s f√°cil con botones")
        print("‚Ä¢ El auto-aprendizaje permite que el modelo se haga preguntas y mejore")
        print("‚Ä¢ La evoluci√≥n crea nuevas versiones mejoradas basadas en el aprendizaje")
        print("‚Ä¢ Puedes interactuar con versiones anteriores para comparar el progreso")
        print("‚Ä¢ La memoria permanente conserva todas las experiencias importantes")


def main():
    """Funci√≥n principal mejorada"""
    parser = argparse.ArgumentParser(description="Modelo de Lenguaje Avanzado con Auto-Aprendizaje y Memoria Permanente")
    parser.add_argument("--nombre", default="modelo_avanzado", help="Nombre del modelo")
    parser.add_argument("--vocab-size", type=int, default=15000, help="Tama√±o del vocabulario")
    parser.add_argument("--embedding-dim", type=int, default=256, help="Dimensi√≥n de embeddings")
    parser.add_argument("--hidden-dim", type=int, default=512, help="Dimensi√≥n de capa oculta")
    parser.add_argument("--learning-rate", type=float, default=0.01, help="Learning rate")
    parser.add_argument("--auto-train", action="store_true", help="Activar auto-entrenamiento")
    parser.add_argument("--auto-improve", action="store_true", help="Activar auto-mejora")
    parser.add_argument("--auto-evolve", action="store_true", help="Activar auto-evoluci√≥n")
    parser.add_argument("--self-question", action="store_true", help="Activar auto-cuestionamiento")
    parser.add_argument("--openai-key", default="", help="API key de OpenAI para evaluaci√≥n")
    parser.add_argument("--debug", action="store_true", help="Activar modo debug")
    parser.add_argument("--gui", action="store_true", help="Iniciar directamente con interfaz gr√°fica")
    
    args = parser.parse_args()
    
    # Crear configuraci√≥n
    config = ModelConfig(
        nombre=args.nombre,
        vocab_size=args.vocab_size,
        embedding_dim=args.embedding_dim,
        hidden_dim=args.hidden_dim,
        learning_rate=args.learning_rate,
        auto_train=args.auto_train,
        auto_improve=args.auto_improve,
        auto_evolution=args.auto_evolve,
        self_questioning=args.self_question,
        openai_api_key=args.openai_key
    )
    
    try:
        # Crear e inicializar modelo
        modelo = ModeloLenguajeMejorado(config)
        modelo.modo_debug = args.debug
        
        print(f"{Colors.GREEN}‚úÖ Modelo inicializado correctamente{Colors.END}")
        print(f"{Colors.CYAN}üìä Vocabulario: {len(modelo.vocabulario):,} palabras{Colors.END}")
        print(f"{Colors.CYAN}üí¨ Conversaciones previas: {len(modelo.conversaciones):,}{Colors.END}")
        print(f"{Colors.CYAN}üß¨ Versiones anteriores: {len(modelo.versiones_anteriores)}{Colors.END}")
        print(f"{Colors.CYAN}ü§î Sesiones de auto-aprendizaje: {len(modelo.sesiones_auto_aprendizaje)}{Colors.END}")
        print(f"{Colors.CYAN}üß† Experiencias en memoria: {len(modelo.memoria_permanente['experiencias_importantes'])}{Colors.END}")
        
        # Mostrar estado de funcionalidades avanzadas
        if modelo.auto_cuestionamiento_activo:
            print(f"{Colors.GREEN}ü§î Auto-cuestionamiento: ACTIVO{Colors.END}")
        if modelo.auto_evolucion_activa:
            print(f"{Colors.GREEN}üß¨ Auto-evoluci√≥n: ACTIVA{Colors.END}")
        if modelo.juez_openai.api_key:
            print(f"{Colors.GREEN}‚öñÔ∏è Evaluaci√≥n con OpenAI: DISPONIBLE{Colors.END}")
        
        print(f"{Colors.PURPLE}üß† MEMORIA PERMANENTE: El modelo NUNCA OLVIDA sus experiencias{Colors.END}")
        
        # Iniciar interfaz
        if args.gui:
            print(f"{Colors.YELLOW}üñ•Ô∏è Iniciando interfaz gr√°fica...{Colors.END}")
            gui = InterfazGrafica(modelo)
            gui.ejecutar()
        else:
            print(f"{Colors.CYAN}üí° Usa /gui para abrir la interfaz con botones{Colors.END}")
            modelo.modo_interactivo()
        
    except KeyboardInterrupt:
        print(f"\n{Colors.YELLOW}üëã Programa interrumpido por el usuario{Colors.END}")
    except Exception as e:
        logger.error(f"Error cr√≠tico: {e}")
        print(f"{Colors.RED}‚ùå Error cr√≠tico: {e}{Colors.END}")
        print(f"{Colors.YELLOW}üîß Verifica la instalaci√≥n y permisos de archivos{Colors.END}")


if __name__ == "__main__":
    main()import numpy as np
import json
import os
import pickle
import inspect
import ast
import subprocess
import sys
from datetime import datetime
import importlib
import shutil
import re
import random
from collections import defaultdict, Counter
import time
import threading
import logging
from typing import Dict, List, Tuple, Optional, Any
import argparse
from dataclasses import dataclass
import asyncio
import aiohttp
import tkinter as tk
from tkinter import ttk, scrolledtext, messagebox, simpledialog
import threading
import queue

# Configurar logging con mejor formato
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# Simulaci√≥n de OpenAI para el ejemplo (reemplazar con la librer√≠a real)
class MockOpenAI:
    def __init__(self, api_key):
        self.api_key = api_key
    
    class ChatCompletion:
        @staticmethod
        async def acreate(**kwargs):
            # Simulaci√≥n de respuesta
            await asyncio.sleep(0.5)  # Simular latencia
            class MockResponse:
                def __init__(self):
                    self.choices = [type('obj', (object,), {
                        'message': type('obj', (object,), {
                            'content': json.dumps({
                                "puntuacion_total": random.randint(6, 10),
                                "coherencia": random.randint(6, 10),
                                "relevancia": random.randint(6, 10),
                                "precision": random.randint(6, 10),
                                "utilidad": random.randint(6, 10),
                                "comentarios": "Respuesta coherente y √∫til",
                                "sugerencias": "Podr√≠a ser m√°s espec√≠fica"
                            })
                        })
                    })()]
            return MockResponse()

# Configuraci√≥n de colores para la terminal
class Colors:
    BLUE = '\033[94m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    PURPLE = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    END = '\033[0m'

@dataclass
class ModelConfig:
    """Configuraci√≥n del modelo"""
    nombre: str = "llm_mejorado"
    vocab_size: int = 15000
    embedding_dim: int = 256
    hidden_dim: int = 512
    learning_rate: float = 0.01
    auto_train: bool = True
    auto_improve: bool = True
    max_response_length: int = 50
    temperature: float = 0.8
    top_p: float = 0.9
    openai_api_key: str = ""
    auto_evolution: bool = True
    self_questioning: bool = True

class InterfazGrafica:
    """Interfaz gr√°fica mejorada con botones"""
    
    def __init__(self, modelo):
        self.modelo = modelo
        self.root = tk.Tk()
        self.root.title(f"Modelo de IA Avanzado - {modelo.nombre}")
        self.root.geometry("1200x800")
        self.root.configure(bg='#2b2b2b')
        
        # Cola para comunicaci√≥n entre threads
        self.message_queue = queue.Queue()
        
        self.setup_gui()
        self.auto_learning_active = False
        
    def setup_gui(self):
        """Configura la interfaz gr√°fica"""
        # Frame principal
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # Estilo
        style = ttk.Style()
        style.theme_use('clam')
        style.configure('Chat.TFrame', background='#3c3c3c')
        style.configure('Button.TButton', padding=10)
        
        # T√≠tulo
        title_label = tk.Label(main_frame, 
                              text=f"ü§ñ {self.modelo.nombre.upper()} v{self.modelo.version}",
                              font=('Arial', 16, 'bold'),
                              bg='#2b2b2b', fg='#00ff88')
        title_label.pack(pady=10)
        
        # Frame de estad√≠sticas
        stats_frame = ttk.Frame(main_frame)
        stats_frame.pack(fill=tk.X, pady=5)
        
        self.stats_label = tk.Label(stats_frame,
                                   text=f"üí¨ Conversaciones: {len(self.modelo.conversaciones)} | "
                                        f"üìö Vocabulario: {len(self.modelo.vocabulario)} | "
                                        f"üß¨ Versiones: {len(self.modelo.versiones_anteriores)}",
                                   bg='#2b2b2b', fg='#ffffff')
        self.stats_label.pack()
        
        # Frame del chat
        chat_frame = ttk.Frame(main_frame, style='Chat.TFrame')
        chat_frame.pack(fill=tk.BOTH, expand=True, pady=10)
        
        # √Årea de mensajes
        self.chat_display = scrolledtext.ScrolledText(chat_frame,
                                                     wrap=tk.WORD,
                                                     font=('Consolas', 11),
                                                     bg='#1e1e1e',
                                                     fg='#ffffff',
                                                     insertbackground='#ffffff',
                                                     selectbackground='#404040')
        self.chat_display.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # Frame de entrada
        input_frame = ttk.Frame(main_frame)
        input_frame.pack(fill=tk.X, pady=5)
        
        # Campo de entrada
        self.input_entry = tk.Entry(input_frame,
                                   font=('Arial', 12),
                                   bg='#404040',
                                   fg='#ffffff',
                                   insertbackground='#ffffff')
        self.input_entry.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 5))
        self.input_entry.bind('<Return>', self.enviar_mensaje)
        
        # Bot√≥n enviar
        send_btn = ttk.Button(input_frame, text="Enviar üì§", command=self.enviar_mensaje)
        send_btn.pack(side=tk.RIGHT)
        
        # Frame de botones principales
        buttons_frame = ttk.Frame(main_frame)
        buttons_frame.pack(fill=tk.X, pady=10)
        
        # Primera fila de botones
        row1 = ttk.Frame(buttons_frame)
        row1.pack(fill=tk.X, pady=2)
        
        ttk.Button(row1, text="ü§î Auto-Aprendizaje", command=self.iniciar_auto_aprendizaje).pack(side=tk.LEFT, padx=2)
        ttk.Button(row1, text="üß¨ Evolucionar", command=self.evolucionar_modelo).pack(side=tk.LEFT, padx=2)
        ttk.Button(row1, text="üë• Hablar con Clon", command=self.hablar_con_clon).pack(side=tk.LEFT, padx=2)
        ttk.Button(row1, text="üìä Estad√≠sticas", command=self.mostrar_estadisticas).pack(side=tk.LEFT, padx=2)
        
        # Segunda fila de botones
        row2 = ttk.Frame(buttons_frame)
        row2.pack(fill=tk.X, pady=2)
        
        ttk.Button(row2, text="üíæ Guardar", command=self.guardar_modelo).pack(side=tk.LEFT, padx=2)
        ttk.Button(row2, text="‚öôÔ∏è Configurar", command=self.configurar_modelo).pack(side=tk.LEFT, padx=2)
        ttk.Button(row2, text="üß™ Tests", command=self.ejecutar_tests).pack(side=tk.LEFT, padx=2)
        ttk.Button(row2, text="üìö Historial", command=self.mostrar_historial).pack(side=tk.LEFT, padx=2)
        
        # Tercera fila de botones
        row3 = ttk.Frame(buttons_frame)
        row3.pack(fill=tk.X, pady=2)
        
        ttk.Button(row3, text="üéì Entrenar", command=self.modo_entrenamiento).pack(side=tk.LEFT, padx=2)
        ttk.Button(row3, text="üßπ Limpiar Chat", command=self.limpiar_chat).pack(side=tk.LEFT, padx=2)
        ttk.Button(row3, text="üîÑ Backup", command=self.crear_backup).pack(side=tk.LEFT, padx=2)
        ttk.Button(row3, text="‚ùå Salir", command=self.salir).pack(side=tk.RIGHT, padx=2)
        
        # Mensaje de bienvenida
        self.agregar_mensaje("ü§ñ Sistema", f"¬°Hola! Soy {self.modelo.nombre}, un modelo de IA avanzado.", "system")
        self.agregar_mensaje("ü§ñ Sistema", "Puedo aprender solo, evolucionar y hablar con mis versiones anteriores.", "system")
        self.agregar_mensaje("ü§ñ Sistema", "Usa los botones de abajo o escribe tu mensaje para comenzar.", "system")
        
        # Iniciar el procesamiento de mensajes
        self.root.after(100, self.procesar_cola_mensajes)
    
    def procesar_cola_mensajes(self):
        """Procesa mensajes de la cola de forma segura"""
        try:
            while True:
                mensaje = self.message_queue.get_nowait()
                self.agregar_mensaje(mensaje['emisor'], mensaje['texto'], mensaje['tipo'])
        except queue.Empty:
            pass
        finally:
            self.root.after(100, self.procesar_cola_mensajes)
    
    def agregar_mensaje(self, emisor, texto, tipo="user"):
        """Agrega un mensaje al chat"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        
        colors = {
            "user": "#00ff88",
            "ai": "#0088ff",
            "system": "#ff8800",
            "error": "#ff0000"
        }
        
        color = colors.get(tipo, "#ffffff")
        
        self.chat_display.config(state=tk.NORMAL)
        self.chat_display.insert(tk.END, f"[{timestamp}] {emisor}: ", f"{tipo}_header")
        self.chat_display.insert(tk.END, f"{texto}\n\n", f"{tipo}_body")
        
        # Configurar colores
        self.chat_display.tag_config(f"{tipo}_header", foreground=color, font=('Arial', 10, 'bold'))
        self.chat_display.tag_config(f"{tipo}_body", foreground="#ffffff", font=('Arial', 10))
        
        self.chat_display.config(state=tk.DISABLED)
        self.chat_display.see(tk.END)
    
    def enviar_mensaje(self, event=None):
        """Env√≠a un mensaje del usuario"""
        mensaje = self.input_entry.get().strip()
        if not mensaje:
            return
        
        self.input_entry.delete(0, tk.END)
        self.agregar_mensaje("üë§ T√∫", mensaje, "user")
        
        # Procesar respuesta en thread separado
        thread = threading.Thread(target=self.procesar_respuesta, args=(mensaje,))
        thread.daemon = True
        thread.start()
    
    def procesar_respuesta(self, mensaje):
        """Procesa la respuesta del modelo en thread separado"""
        try:
            respuesta = self.modelo.procesar_entrada(mensaje)
            self.message_queue.put({
                'emisor': f'ü§ñ {self.modelo.nombre}',
                'texto': respuesta,
                'tipo': 'ai'
            })
            self.actualizar_estadisticas()
        except Exception as e:
            self.message_queue.put({
                'emisor': '‚ùå Error',
                'texto': f"Error procesando mensaje: {str(e)}",
                'tipo': 'error'
            })
    
    def iniciar_auto_aprendizaje(self):
        """Inicia una sesi√≥n de auto-aprendizaje"""
        if self.auto_learning_active:
            messagebox.showwarning("Advertencia", "Ya hay una sesi√≥n de auto-aprendizaje activa")
            return
        
        duracion = simpledialog.askinteger("Auto-Aprendizaje", 
                                         "¬øCu√°ntos minutos de auto-aprendizaje?", 
                                         initialvalue=5, minvalue=1, maxvalue=60)
        if duracion:
            self.auto_learning_active = True
            self.agregar_mensaje("ü§î Sistema", f"Iniciando auto-aprendizaje por {duracion} minutos...", "system")
            
            thread = threading.Thread(target=self.ejecutar_auto_aprendizaje, args=(duracion,))
            thread.daemon = True
            thread.start()
    
    def ejecutar_auto_aprendizaje(self, duracion):
        """Ejecuta el auto-aprendizaje en thread separado"""
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(self.modelo.sesion_auto_aprendizaje(duracion))
            
            self.message_queue.put({
                'emisor': '‚úÖ Sistema',
                'texto': f"Auto-aprendizaje completado. Realizadas {duracion} iteraciones de mejora.",
                'tipo': 'system'
            })
        except Exception as e:
            self.message_queue.put({
                'emisor': '‚ùå Error',
                'texto': f"Error en auto-aprendizaje: {str(e)}",
                'tipo': 'error'
            })
        finally:
            self.auto_learning_active = False
    
    def evolucionar_modelo(self):
        """Crea una nueva versi√≥n evolucionada del modelo"""
        respuesta = messagebox.askyesno("Evoluci√≥n", 
                                       "¬øCrear una nueva versi√≥n evolucionada del modelo?\n"
                                       "Esto puede tomar unos momentos.")
        if respuesta:
            self.agregar_mensaje("üß¨ Sistema", "Creando nueva versi√≥n evolucionada...", "system")
            
            thread = threading.Thread(target=self.proceso_evolucion)
            thread.daemon = True
            thread.start()
    
    def proceso_evolucion(self):
        """Proceso de evoluci√≥n en thread separado"""
        try:
            nueva_version = self.modelo.crear_version_de_si_mismo()
            self.message_queue.put({
                'emisor': 'üß¨ Sistema',
                'texto': f"Nueva versi√≥n '{nueva_version.nombre}' creada exitosamente.",
                'tipo': 'system'
            })
        except Exception as e:
            self.message_queue.put({
                'emisor': '‚ùå Error',
                'texto': f"Error en evoluci√≥n: {str(e)}",
                'tipo': 'error'
            })
    
    def hablar_con_clon(self):
        """Permite hablar con versiones anteriores"""
        versiones = self.modelo.listar_versiones_disponibles()
        if not versiones:
            messagebox.showinfo("Info", "No hay versiones anteriores disponibles")
            return
        
        # Crear ventana de selecci√≥n
        dialog = tk.Toplevel(self.root)
        dialog.title("Seleccionar Versi√≥n")
        dialog.geometry("300x200")
        dialog.configure(bg='#2b2b2b')
        
        tk.Label(dialog, text="Selecciona una versi√≥n:", 
                bg='#2b2b2b', fg='#ffffff', font=('Arial', 12)).pack(pady=10)
        
        listbox = tk.Listbox(dialog, bg='#404040', fg='#ffffff')
        for version in versiones:
            listbox.insert(tk.END, version)
        listbox.pack(pady=10, padx=20, fill=tk.BOTH, expand=True)
        
        def iniciar_dialogo():
            selection = listbox.curselection()
            if selection:
                version_seleccionada = versiones[selection[0]]
                dialog.destroy()
                self.agregar_mensaje("üë• Sistema", f"Iniciando di√°logo con {version_seleccionada}...", "system")
                
                thread = threading.Thread(target=self.ejecutar_dialogo_clon, args=(version_seleccionada,))
                thread.daemon = True
                thread.start()
        
        ttk.Button(dialog, text="Iniciar Di√°logo", command=iniciar_dialogo).pack(pady=10)
    
    def ejecutar_dialogo_clon(self, version_name):
        """Ejecuta el di√°logo con clon en thread separado"""
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(self.modelo.interactuar_con_version_anterior(version_name))
            
            self.message_queue.put({
                'emisor': 'üë• Sistema',
                'texto': f"Di√°logo con {version_name} completado.",
                'tipo': 'system'
            })
        except Exception as e:
            self.message_queue.put({
                'emisor': '‚ùå Error',
                'texto': f"Error en di√°logo: {str(e)}",
                'tipo': 'error'
            })
    
    def mostrar_estadisticas(self):
        """Muestra ventana de estad√≠sticas"""
        stats_window = tk.Toplevel(self.root)
        stats_window.title("Estad√≠sticas del Modelo")
        stats_window.geometry("600x400")
        stats_window.configure(bg='#2b2b2b')
        
        text_area = scrolledtext.ScrolledText(stats_window, 
                                            bg='#1e1e1e', fg='#ffffff',
                                            font=('Consolas', 10))
        text_area.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # Generar estad√≠sticas
        stats = f"""
üìä ESTAD√çSTICAS DEL MODELO {self.modelo.nombre.upper()}
{'='*50}

üìã INFORMACI√ìN GENERAL:
   ‚Ä¢ Nombre: {self.modelo.nombre}
   ‚Ä¢ Versi√≥n: {self.modelo.version}
   ‚Ä¢ Vocabulario: {len(self.modelo.vocabulario):,} palabras
   ‚Ä¢ Conversaciones: {len(self.modelo.conversaciones):,}

üèóÔ∏è ARQUITECTURA:
   ‚Ä¢ Embedding: {self.modelo.vocab_size:,} x {self.modelo.embedding_dim}
   ‚Ä¢ Hidden Layer: {self.modelo.embedding_dim} x {self.modelo.hidden_dim}
   ‚Ä¢ Output Layer: {self.modelo.hidden_dim} x {self.modelo.vocab_size:,}

‚öôÔ∏è CONFIGURACI√ìN:
   ‚Ä¢ Auto-entrenamiento: {'üü¢ ACTIVO' if self.modelo.auto_entrenamiento_activo else 'üî¥ INACTIVO'}
   ‚Ä¢ Auto-mejora: {'üü¢ ACTIVA' if self.modelo.auto_mejora_activa else 'üî¥ INACTIVA'}
   ‚Ä¢ Auto-evoluci√≥n: {'üü¢ ACTIVA' if self.modelo.auto_evolucion_activa else 'üî¥ INACTIVA'}
   ‚Ä¢ Auto-cuestionamiento: {'üü¢ ACTIVO' if self.modelo.auto_cuestionamiento_activo else 'üî¥ INACTIVO'}
   ‚Ä¢ Learning Rate: {self.modelo.learning_rate:.6f}

üß† AUTO-APRENDIZAJE:
   ‚Ä¢ Sesiones realizadas: {len(self.modelo.sesiones_auto_aprendizaje)}
   ‚Ä¢ Versiones anteriores: {len(self.modelo.versiones_anteriores)}
   ‚Ä¢ Preguntas auto-generadas: {len(self.modelo.preguntas_auto_generadas)}

‚è±Ô∏è RENDIMIENTO:
"""
        
        if self.modelo.metricas_rendimiento['tiempo_respuesta']:
            tiempos = self.modelo.metricas_rendimiento['tiempo_respuesta']
            stats += f"""   ‚Ä¢ Tiempo promedio: {np.mean(tiempos):.3f}s
   ‚Ä¢ Tiempo m√≠nimo: {np.min(tiempos):.3f}s
   ‚Ä¢ Tiempo m√°ximo: {np.max(tiempos):.3f}s"""
        else:
            stats += "   ‚Ä¢ No hay datos de rendimiento disponibles"
        
        text_area.insert(tk.END, stats)
        text_area.config(state=tk.DISABLED)
    
    def guardar_modelo(self):
        """Guarda el modelo"""
        if self.modelo.guardar_modelo():
            messagebox.showinfo("√âxito", "Modelo guardado exitosamente")
            self.actualizar_estadisticas()
        else:
            messagebox.showerror("Error", "Error al guardar el modelo")
    
    def configurar_modelo(self):
        """Abre ventana de configuraci√≥n"""
        config_window = tk.Toplevel(self.root)
        config_window.title("Configuraci√≥n del Modelo")
        config_window.geometry("400x500")
        config_window.configure(bg='#2b2b2b')
        
        # Variables de configuraci√≥n
        auto_train_var = tk.BooleanVar(value=self.modelo.auto_entrenamiento_activo)
        auto_improve_var = tk.BooleanVar(value=self.modelo.auto_mejora_activa)
        auto_evolve_var = tk.BooleanVar(value=self.modelo.auto_evolucion_activa)
        auto_question_var = tk.BooleanVar(value=self.modelo.auto_cuestionamiento_activo)
        
        tk.Label(config_window, text="‚öôÔ∏è CONFIGURACI√ìN", 
                bg='#2b2b2b', fg='#00ff88', font=('Arial', 14, 'bold')).pack(pady=10)
        
        # Checkboxes
        tk.Checkbutton(config_window, text="üéì Auto-entrenamiento", 
                      variable=auto_train_var, bg='#2b2b2b', fg='#ffffff',
                      selectcolor='#404040').pack(pady=5, anchor='w', padx=20)
        
        tk.Checkbutton(config_window, text="üöÄ Auto-mejora", 
                      variable=auto_improve_var, bg='#2b2b2b', fg='#ffffff',
                      selectcolor='#404040').pack(pady=5, anchor='w', padx=20)
        
        tk.Checkbutton(config_window, text="üß¨ Auto-evoluci√≥n", 
                      variable=auto_evolve_var, bg='#2b2b2b', fg='#ffffff',
                      selectcolor='#404040').pack(pady=5, anchor='w', padx=20)
        
        tk.Checkbutton(config_window, text="ü§î Auto-cuestionamiento", 
                      variable=auto_question_var, bg='#2b2b2b', fg='#ffffff',
                      selectcolor='#404040').pack(pady=5, anchor='w', padx=20)
        
        # Learning Rate
        tk.Label(config_window, text="üìä Learning Rate:", 
                bg='#2b2b2b', fg='#ffffff').pack(pady=(20,5), anchor='w', padx=20)
        
        lr_var = tk.StringVar(value=str(self.modelo.learning_rate))
        lr_entry = tk.Entry(config_window, textvariable=lr_var, bg='#404040', fg='#ffffff')
        lr_entry.pack(pady=5, padx=20, fill='x')
        
        # Temperature
        tk.Label(config_window, text="üå°Ô∏è Temperature:", 
                bg='#2b2b2b', fg='#ffffff').pack(pady=(10,5), anchor='w', padx=20)
        
        temp_var = tk.StringVar(value=str(self.modelo.config.temperature))
        temp_entry = tk.Entry(config_window, textvariable=temp_var, bg='#404040', fg='#ffffff')
        temp_entry.pack(pady=5, padx=20, fill='x')
        
        def aplicar_configuracion():
            try:
                self.modelo.auto_entrenamiento_activo = auto_train_var.get()
                self.modelo.auto_mejora_activa = auto_improve_var.get()
                self.modelo.auto_evolucion_activa = auto_evolve_var.get()
                self.modelo.auto_cuestionamiento_activo = auto_question_var.get()
                
                new_lr = float(lr_var.get())
                if 0.0001 <= new_lr <= 1.0:
                    self.modelo.learning_rate = new_lr
                
                new_temp = float(temp_var.get())
                if 0.1 <= new_temp <= 2.0:
                    self.modelo.config.temperature = new_temp
                
                messagebox.showinfo("√âxito", "Configuraci√≥n aplicada")
                config_window.destroy()
                
            except ValueError:
                messagebox.showerror("Error", "Valores inv√°lidos")
        
        ttk.Button(config_window, text="Aplicar", command=aplicar_configuracion).pack(pady=20)
    
    def ejecutar_tests(self):
        """Ejecuta tests del modelo"""
        self.agregar_mensaje("üß™ Sistema", "Ejecutando tests de validaci√≥n...", "system")
        
        thread = threading.Thread(target=self.proceso_tests)
        thread.daemon = True
        thread.start()
    
    def proceso_tests(self):
        """Ejecuta tests en thread separado"""
        try:
            # Simular tests
            tests = [
                "Test b√°sico de respuesta",
                "Test de tiempo de respuesta", 
                "Test de entrada vac√≠a",
                "Test de entrada larga",
                "Test de caracteres especiales"
            ]
            
            resultados = []
            for test in tests:
                time.sleep(0.5)  # Simular tiempo de test
                exito = random.choice([True, True, True, False])  # 75% √©xito
                resultados.append(exito)
                
                estado = "‚úÖ PAS√ì" if exito else "‚ùå FALL√ì"
                self.message_queue.put({
                    'emisor': 'üß™ Test',
                    'texto': f"{test}: {estado}",
                    'tipo': 'system'
                })
            
            exitosos = sum(resultados)
            total = len(resultados)
            porcentaje = (exitosos / total) * 100
            
            self.message_queue.put({
                'emisor': 'üìä Resultado',
                'texto': f"Tests completados: {exitosos}/{total} ({porcentaje:.1f}%) exitosos",
                'tipo': 'system'
            })
            
        except Exception as e:
            self.message_queue.put({
                'emisor': '‚ùå Error',
                'texto': f"Error ejecutando tests: {str(e)}",
                'tipo': 'error'
            })
    
    def mostrar_historial(self):
        """Muestra el historial de conversaciones"""
        hist_window = tk.Toplevel(self.root)
        hist_window.title("Historial de Conversaciones")
        hist_window.geometry("800x600")
        hist_window.configure(bg='#2b2b2b')
        
        text_area = scrolledtext.ScrolledText(hist_window, 
                                            bg='#1e1e1e', fg='#ffffff',
                                            font=('Consolas', 10))
        text_area.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        if not self.modelo.conversaciones:
            text_area.insert(tk.END, "üì≠ No hay conversaciones registradas")
        else:
            ultimas = self.modelo.conversaciones[-20:]  # √öltimas 20
            for i, conv in enumerate(ultimas, 1):
                timestamp = conv['timestamp'][:19].replace('T', ' ')
                tiempo_resp = conv.get('tiempo_respuesta', 0)
                
                text_area.insert(tk.END, f"\n{i}. {timestamp} (‚è±Ô∏è {tiempo_resp:.3f}s)\n")
                text_area.insert(tk.END, f"üë§ Usuario: {conv['entrada']}\n")
                text_area.insert(tk.END, f"ü§ñ Modelo: {conv['respuesta']}\n")
                text_area.insert(tk.END, "-" * 50 + "\n")
        
        text_area.config(state=tk.DISABLED)
    
    def modo_entrenamiento(self):
        """Abre modo de entrenamiento"""
        train_window = tk.Toplevel(self.root)
        train_window.title("Modo Entrenamiento")
        train_window.geometry("600x400")
        train_window.configure(bg='#2b2b2b')
        
        tk.Label(train_window, text="üéì MODO ENTRENAMIENTO", 
                bg='#2b2b2b', fg='#00ff88', font=('Arial', 14, 'bold')).pack(pady=10)
        
        tk.Label(train_window, text="Ingresa frases para entrenar el modelo:", 
                bg='#2b2b2b', fg='#ffffff').pack(pady=5)
        
        # √Årea de entrada
        entrada_frame = ttk.Frame(train_window)
        entrada_frame.pack(fill=tk.X, padx=20, pady=10)
        
        entrada_text = tk.Text(entrada_frame, height=3, bg='#404040', fg='#ffffff')
        entrada_text.pack(fill=tk.X)
        
        # √Årea de resultados
        resultado_text = scrolledtext.ScrolledText(train_window, height=15,
                                                  bg='#1e1e1e', fg='#ffffff')
        resultado_text.pack(fill=tk.BOTH, expand=True, padx=20, pady=10)
        
        def entrenar_frase():
            frase = entrada_text.get("1.0", tk.END).strip()
            if frase:
                # Simular entrenamiento
                tokens = len(frase.split())
                error_simulado = random.uniform(0.1, 1.0)
                
                resultado_text.insert(tk.END, f"‚úÖ Entrenando: '{frase}'\n")
                resultado_text.insert(tk.END, f"   üìä Tokens: {tokens}\n")
                resultado_text.insert(tk.END, f"   üìâ Error: {error_simulado:.4f}\n\n")
                resultado_text.see(tk.END)
                
                entrada_text.delete("1.0", tk.END)
        
        ttk.Button(entrada_frame, text="üéì Entrenar", command=entrenar_frase).pack(pady=5)
    
    def limpiar_chat(self):
        """Limpia el √°rea de chat"""
        self.chat_display.config(state=tk.NORMAL)
        self.chat_display.delete(1.0, tk.END)
        self.chat_display.config(state=tk.DISABLED)
        self.agregar_mensaje("üßπ Sistema", "Chat limpiado", "system")
    
    def crear_backup(self):
        """Crea un backup del modelo"""
        if self.modelo.crear_backup():
            messagebox.showinfo("√âxito", "Backup creado exitosamente")
        else:
            messagebox.showerror("Error", "Error creando backup")
    
    def actualizar_estadisticas(self):
        """Actualiza las estad√≠sticas mostradas"""
        self.stats_label.config(
            text=f"üí¨ Conversaciones: {len(self.modelo.conversaciones)} | "
                 f"üìö Vocabulario: {len(self.modelo.vocabulario)} | "
                 f"üß¨ Versiones: {len(self.modelo.versiones_anteriores)}"
        )
    
    def salir(self):
        """Cierra la aplicaci√≥n"""
        if messagebox.askyesno("Salir", "¬øGuardar el modelo antes de salir?"):
            self.modelo.guardar_modelo()
        self.root.quit()
    
    def ejecutar(self):
        """Ejecuta la interfaz gr√°fica"""
        self.root.mainloop()

class InterfazMejorada:
    """Interfaz mejorada para el modelo de lenguaje"""
    
    def __init__(self):
        self.ancho_terminal = self._obtener_ancho_terminal()
        self.historial_comando = []
        self.modo_debug = False
        
    def _obtener_ancho_terminal(self):
        """Obtiene el ancho de la terminal"""
        try:
            return os.get_terminal_size().columns
        except:
            return 80
    
    def imprimir_banner(self, texto: str, color: str = Colors.BLUE, caracter: str = "="):
        """Imprime un banner decorado"""
        ancho = min(self.ancho_terminal, 80)
        print(f"\n{color}{caracter * ancho}")
        texto_centrado = texto.center(ancho)
        print(f"{texto_centrado}")
        print(f"{caracter * ancho}{Colors.END}")
    
    def imprimir_seccion(self, titulo: str, contenido: str = "", color: str = Colors.CYAN):
        """Imprime una secci√≥n con formato"""
        print(f"\n{color}{Colors.BOLD}üìã {titulo.upper()}{Colors.END}")
        print(f"{color}{'‚îÄ' * (len(titulo) + 4)}{Colors.END}")
        if contenido:
            print(f"{contenido}")
    
    def imprimir_estadistica(self, etiqueta: str, valor: Any, color: str = Colors.WHITE):
        """Imprime una estad√≠stica formateada"""
        print(f"{color}   {etiqueta:<25} {Colors.BOLD}{valor}{Colors.END}")
    
    def imprimir_progreso(self, actual: int, total: int, descripcion: str = ""):
        """Imprime una barra de progreso"""
        porcentaje = (actual / total) * 100
        barra_llena = int(30 * actual / total)
        barra = "‚ñà" * barra_llena + "‚ñë" * (30 - barra_llena)
        
        print(f"\r{Colors.YELLOW}[{barra}] {porcentaje:.1f}% {descripcion}{Colors.END}", end="", flush=True)
        if actual == total:
            print()  # Nueva l√≠nea al completar
    
    def solicitar_entrada(self, prompt: str, color: str = Colors.GREEN) -> str:
        """Solicita entrada del usuario con formato"""
        try:
            return input(f"{color}{prompt}{Colors.END}").strip()
        except KeyboardInterrupt:
            print(f"\n{Colors.YELLOW}‚ö†Ô∏è  Operaci√≥n cancelada{Colors.END}")
            return ""
    
    def mostrar_menu(self, opciones: Dict[str, str], titulo: str = "OPCIONES DISPONIBLES"):
        """Muestra un men√∫ formateado"""
        self.imprimir_seccion(titulo, color=Colors.PURPLE)
        
        for key, descripcion in opciones.items():
            icono = self._obtener_icono_comando(key)
            print(f"   {Colors.WHITE}{key:<15} {icono} {descripcion}{Colors.END}")
    
    def _obtener_icono_comando(self, comando: str) -> str:
        """Obtiene un icono para cada comando"""
        iconos = {
            '/help': '‚ùì',
            '/stats': 'üìä',
            '/train': 'üéì',
            '/improve': 'üöÄ',
            '/save': 'üíæ',
            '/load': 'üìÇ',
            '/clear': 'üßπ',
            '/history': 'üìö',
            '/config': '‚öôÔ∏è',
            '/test': 'üß™',
            '/export': 'üì§',
            '/debug': 'üêõ',
            '/evolve': 'üß¨',
            '/self_learn': 'ü§î',
            '/clone': 'üë•',
            '/quit': 'üëã'
        }
        return iconos.get(comando, '‚ñ∂Ô∏è')

class JuezOpenAI:
    """Clase para interactuar con OpenAI como juez de respuestas"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        if api_key:
            self.openai = MockOpenAI(api_key)  # Usar mock para el ejemplo
    
    async def evaluar_respuesta(self, pregunta: str, respuesta: str, contexto: str = "") -> Dict[str, Any]:
        """Eval√∫a una respuesta usando OpenAI"""
        if not self.api_key:
            return {"error": "API key de OpenAI no configurada"}
        
        try:
            prompt = f"""
            Como un juez experto en inteligencia artificial, eval√∫a la siguiente respuesta:
            
            PREGUNTA: {pregunta}
            RESPUESTA: {respuesta}
            CONTEXTO: {contexto}
            
            Eval√∫a en una escala de 1-10 considerando:
            - Coherencia (¬øLa respuesta tiene sentido?)
            - Relevancia (¬øResponde a la pregunta?)
            - Precisi√≥n (¬øEs factualmente correcta?)
            - Utilidad (¬øEs √∫til para el usuario?)
            
            Devuelve tu evaluaci√≥n en formato JSON:
            {{
                "puntuacion_total": [1-10],
                "coherencia": [1-10],
                "relevancia": [1-10],
                "precision": [1-10],
                "utilidad": [1-10],
                "comentarios": "comentarios detallados",
                "sugerencias": "sugerencias de mejora"
            }}
            """
            
            response = await self.openai.ChatCompletion.acreate(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500,
                temperature=0.3
            )
            
            resultado = response.choices[0].message.content
            return json.loads(resultado)
            
        except Exception as e:
            return {"error": f"Error evaluando con OpenAI: {str(e)}"}
    
    async def generar_pregunta_critica(self, tema: str) -> str:
        """Genera una pregunta cr√≠tica sobre un tema"""
        if not self.api_key:
            preguntas_default = [
                f"¬øCu√°les son las implicaciones √©ticas de {tema}?",
                f"¬øC√≥mo puede {tema} impactar el futuro de la humanidad?",
                f"¬øQu√© desaf√≠os presenta {tema} en la sociedad actual?",
                f"¬øCu√°les son los aspectos m√°s importantes de {tema}?",
                f"¬øC√≥mo se relaciona {tema} con otros campos del conocimiento?"
            ]
            return random.choice(preguntas_default)
        
        try:
            prompt = f"""
            Genera una pregunta cr√≠tica y profunda sobre el tema: {tema}
            
            La pregunta debe:
            - Ser espec√≠fica y detallada
            - Requerir an√°lisis cr√≠tico
            - Tener m√∫ltiples perspectivas posibles
            - Ser educativa y constructiva
            
            Devuelve solo la pregunta, sin explicaciones adicionales.
            """
            
            response = await self.openai.ChatCompletion.acreate(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=150,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"¬øQu√© opinas sobre {tema} y cu√°les son sus implicaciones?"

class GeneradorContexto:
    """Clase auxiliar para generar contexto mejorado"""
    
    def __init__(self):
        self.contexto_global = []
        self.temas_recientes = []
    
    def actualizar_contexto(self, entrada: str, respuesta: str):
        """Actualiza el contexto global de la conversaci√≥n"""
        self.contexto_global.append({
            'entrada': entrada,
            'respuesta': respuesta,
            'timestamp': datetime.now()
        })
        
        # Mantener solo los √∫ltimos 10 intercambios
        if len(self.contexto_global) > 10:
            self.contexto_global.pop(0)
    
    def obtener_contexto_relevante(self, entrada_actual: str) -> str:
        """Obtiene contexto relevante para la entrada actual"""
        if not self.contexto_global:
            return ""
        
        # Buscar temas relacionados en el contexto reciente
        palabras_entrada = set(entrada_actual.lower().split())
        contexto_relevante = []
        
        for intercambio in self.contexto_global[-3:]:  # √öltimos 3 intercambios
            palabras_prev = set(intercambio['entrada'].lower().split())
            if palabras_entrada.intersection(palabras_prev):
                contexto_relevante.append(intercambio)
        
        return contexto_relevante

class ModeloLenguajeMejorado:
    """
    Modelo de lenguaje mejorado con interfaz avanzada y mejores capacidades de respuesta
    """
    
    def __init__(self, config: ModelConfig = None):
        self.config = config or ModelConfig()
        self.interfaz = InterfazMejorada()
        
        # Configuraci√≥n b√°sica
        self.nombre = self.config.nombre
        self.vocab_size = self.config.vocab_size
        self.embedding_dim = self.config.embedding_dim
        self.hidden_dim = self.config.hidden_dim
        self.learning_rate = self.config.learning_rate
        self.version = "3.0.0"
        
        # Archivos de persistencia
        self._configurar_archivos()
        
        # Estado del modelo
        self.vocabulario = {"<PAD>": 0, "<UNK>": 1, "<START>": 2, "<END>": 3, "<MASK>": 4}
        self.vocabulario_inverso = {0: "<PAD>", 1: "<UNK>", 2: "<START>", 3: "<END>", 4: "<MASK>"}
        self.contador_vocab = 5
        
        # Datos y m√©tricas
        self.conversaciones = []
        self.historial_error = []
        self.contexto_conversacion = []
        self.metricas_rendimiento = {
            'tiempo_respuesta': [],
            'precision_respuestas': [],
            'satisfaccion_usuario': [],
            'complejidad_respuestas': []
        }
        
        # Sistema de respuestas inteligente mejorado
        self.base_conocimiento = self._inicializar_base_conocimiento()
        self.patrones_respuesta = self._inicializar_patrones_respuesta()
        self.generador_contexto = GeneradorContexto()
        
        # Configuraci√≥n avanzada
        self.auto_entrenamiento_activo = self.config.auto_train
        self.auto_mejora_activa = self.config.auto_improve
        self.modo_debug = False
        
        # Nuevas funcionalidades de auto-aprendizaje
        self.juez_openai = JuezOpenAI(self.config.openai_api_key)
        self.versiones_anteriores = []
        self.preguntas_auto_generadas = []
        self.sesiones_auto_aprendizaje = []
        self.auto_evolucion_activa = self.config.auto_evolution
        self.auto_cuestionamiento_activo = self.config.self_questioning
        
        # Memoria persistente - NUNCA SE OLVIDA
        self.memoria_permanente = {
            'experiencias_importantes': [],
            'lecciones_aprendidas': [],
            'patrones_detectados': [],
            'mejoras_realizadas': []
        }
        
        # Inicializar modelo
        self._inicializar_modelo()
        
        # Mensaje de bienvenida
        self.interfaz.imprimir_banner(f"MODELO DE LENGUAJE AVANZADO v{self.version}", Colors.BLUE)
        logger.info(f"ü§ñ Modelo '{self.nombre}' inicializado correctamente")
    
    def _configurar_archivos(self):
        """Configura los archivos de persistencia"""
        self.directorio_base = f"{self.nombre}_data"
        os.makedirs(self.directorio_base, exist_ok=True)
        
        self.archivos = {
            'pesos': f"{self.directorio_base}/pesos.pkl",
            'vocabulario': f"{self.directorio_base}/vocabulario.json",
            'conversaciones': f"{self.directorio_base}/conversaciones.json",
            'config': f"{self.directorio_base}/config.json",
            'backups': f"{self.directorio_base}/backups/",
            'versiones': f"{self.directorio_base}/versiones/",
            'auto_aprendizaje': f"{self.directorio_base}/auto_aprendizaje.json",
            'memoria_permanente': f"{self.directorio_base}/memoria_permanente.json"
        }
        
        for carpeta in ['backups', 'versiones']:
            os.makedirs(self.archivos[carpeta], exist_ok=True)
    
    def _inicializar_base_conocimiento(self) -> Dict[str, Any]:
        """Inicializa la base de conocimiento del modelo"""
        return {
            'definiciones': {
                'inteligencia_artificial': "Campo de la inform√°tica que busca crear sistemas capaces de realizar tareas que normalmente requieren inteligencia humana.",
                'machine_learning': "Subcampo de la IA que permite a las m√°quinas aprender y mejorar autom√°ticamente a partir de la experiencia.",
                'deep_learning': "T√©cnica de machine learning basada en redes neuronales artificiales con m√∫ltiples capas.",
                'nlp': "Procesamiento de Lenguaje Natural - √°rea que combina ling√º√≠stica e inform√°tica para que las m√°quinas entiendan el lenguaje humano."
            },
            'hechos': {
                'python': "Lenguaje de programaci√≥n de alto nivel, interpretado y de prop√≥sito general.",
                'algoritmos': "Secuencia finita de instrucciones bien definidas para resolver un problema.",
                'datos': "Informaci√≥n procesada y organizada que puede ser utilizada para tomar decisiones."
            },
            'conceptos_tecnicos': {
                'neural_network': "Red de nodos interconectados que simula el funcionamiento del cerebro humano.",
                'gradient_descent': "Algoritmo de optimizaci√≥n usado para minimizar funciones de costo.",
                'backpropagation': "M√©todo para entrenar redes neuronales propagando errores hacia atr√°s."
            }
        }
    
    def _inicializar_patrones_respuesta(self) -> Dict[str, Any]:
        """Inicializa patrones de respuesta m√°s sofisticados"""
        return {
            'saludo': {
                'triggers': ['hola', 'buenos d√≠as', 'buenas tardes', 'hey', 'hi', 'saludos'],
                'responses': [
                    "¬°Hola! Soy un modelo de lenguaje avanzado dise√±ado para mantener conversaciones inteligentes y ayudarte con informaci√≥n. ¬øEn qu√© puedo asistirte hoy?",
                    "¬°Saludos! Estoy aqu√≠ para conversar contigo y proporcionarte informaci√≥n √∫til. ¬øQu√© te interesa saber?",
                    "¬°Qu√© tal! Me alegra poder conversar contigo. Soy capaz de discutir una amplia variedad de temas. ¬øSobre qu√© te gustar√≠a hablar?"
                ],
                'contexto': 'inicial'
            },
            'identidad': {
                'triggers': ['qu√© eres', 'qui√©n eres', 'pres√©ntate', 'sobre ti'],
                'responses': [
                    "Soy un modelo de lenguaje avanzado creado para mantener conversaciones naturales y proporcionar informaci√≥n √∫til. Utilizo t√©cnicas de procesamiento de lenguaje natural para entender y responder a tus preguntas de manera coherente.",
                    "Me llamo {nombre} y soy un sistema de inteligencia artificial especializado en conversaci√≥n. Puedo ayudarte con preguntas, explicaciones, an√°lisis de temas y mantener di√°logos interesantes sobre diversos temas.",
                    "Soy un asistente de IA conversacional que combina conocimiento general con capacidades de di√°logo natural. Mi objetivo es ser √∫til, informativo y mantener conversaciones enriquecedoras."
                ],
                'contexto': 'autodescripcion'
            },
            'capacidades': {
                'triggers': ['qu√© puedes hacer', 'capacidades', 'funciones', 'habilidades'],
                'responses': [
                    "Puedo ayudarte con m√∫ltiples tareas: responder preguntas, explicar conceptos, mantener conversaciones, analizar informaci√≥n, proporcionar definiciones y discutir una amplia gama de temas desde ciencia hasta cultura general.",
                    "Mis capacidades incluyen: procesamiento de lenguaje natural, an√°lisis de texto, generaci√≥n de respuestas coherentes, explicaci√≥n de conceptos complejos, y mantenimiento de contexto conversacional.",
                    "Estoy dise√±ado para: conversar de manera natural, proporcionar informaci√≥n precisa, explicar temas complejos de forma comprensible, ayudar con an√°lisis y razonamiento, y adaptarme al estilo de conversaci√≥n que prefieras."
                ],
                'contexto': 'funcional'
            },
            'conocimiento': {
                'triggers': ['sabes sobre', 'conoces', 'informaci√≥n sobre', 'h√°blame de'],
                'responses': [
                    "Tengo conocimientos sobre una amplia variedad de temas incluyendo ciencia, tecnolog√≠a, historia, cultura, programaci√≥n y m√°s. ¬øSobre qu√© tema espec√≠fico te gustar√≠a que te hable?",
                    "Mi base de conocimiento abarca m√∫ltiples disciplinas. Puedo proporcionarte informaci√≥n detallada, explicaciones y an√°lisis sobre el tema que te interese. ¬øQu√© te gustar√≠a explorar?",
                    "Cuento con informaci√≥n sobre diversos campos del conocimiento. Desde conceptos t√©cnicos hasta temas generales, estoy preparado para ayudarte. ¬øHay algo espec√≠fico que quieras saber?"
                ],
                'contexto': 'informativo'
            },
            'agradecimiento': {
                'triggers': ['gracias', 'muchas gracias', 'te agradezco', 'thank you'],
                'responses': [
                    "¬°De nada! Me alegra poder ayudarte. Si tienes m√°s preguntas o quieres continuar la conversaci√≥n, estar√© aqu√≠.",
                    "Es un placer ayudarte. No dudes en preguntarme cualquier cosa m√°s que necesites saber.",
                    "¬°Con gusto! Siempre estoy disponible para asistirte. ¬øHay algo m√°s en lo que pueda ayudarte?"
                ],
                'contexto': 'social'
            }
        }
    
    def _inicializar_modelo(self):
        """Inicializa o carga el modelo"""
        if self._existe_modelo_guardado():
            self._cargar_modelo()
        else:
            self._crear_modelo_nuevo()
            logger.info("üÜï Modelo nuevo creado e inicializado")
    
    def _existe_modelo_guardado(self) -> bool:
        """Verifica si existe un modelo guardado"""
        return os.path.exists(self.archivos['pesos']) and os.path.exists(self.archivos['vocabulario'])
    
    def _cargar_modelo(self):
        """Carga un modelo existente"""
        try:
            # Cargar pesos
            with open(self.archivos['pesos'], 'rb') as f:
                datos = pickle.load(f)
                self.W_embedding = datos['W_embedding']
                self.W_hidden = datos['W_hidden']
                self.b_hidden = datos['b_hidden']
                self.W_output = datos['W_output']
                self.b_output = datos['b_output']
            
            # Cargar vocabulario
            with open(self.archivos['vocabulario'], 'r', encoding='utf-8') as f:
                vocab_data = json.load(f)
                self.vocabulario = vocab_data['vocabulario']
                self.vocabulario_inverso = vocab_data['vocabulario_inverso']
                self.contador_vocab = vocab_data['contador_vocab']
            
            # Cargar conversaciones existentes
            if os.path.exists(self.archivos['conversaciones']):
                with open(self.archivos['conversaciones'], 'r', encoding='utf-8') as f:
                    self.conversaciones = json.load(f)
            
            # Cargar datos de auto-aprendizaje si existen
            if os.path.exists(self.archivos['auto_aprendizaje']):
                with open(self.archivos['auto_aprendizaje'], 'r', encoding='utf-8') as f:
                    auto_data = json.load(f)
                    self.preguntas_auto_generadas = auto_data.get('preguntas', [])
                    self.sesiones_auto_aprendizaje = auto_data.get('sesiones', [])
                    self.versiones_anteriores = auto_data.get('versiones_anteriores', [])
            
            # Cargar memoria permanente - NUNCA SE OLVIDA
            if os.path.exists(self.archivos['memoria_permanente']):
                with open(self.archivos['memoria_permanente'], 'r', encoding='utf-8') as f:
                    self.memoria_permanente = json.load(f)
            
            logger.info("‚úÖ Modelo cargado exitosamente")
        except Exception as e:
            logger.error(f"‚ùå Error cargando modelo: {e}")
            self._crear_modelo_nuevo()
    
    def _crear_modelo_nuevo(self):
        """Crea un nuevo modelo con inicializaci√≥n mejorada"""
        # Inicializaci√≥n He para mejor convergencia
        self.W_embedding = np.random.randn(self.vocab_size, self.embedding_dim) * np.sqrt(2.0 / self.vocab_size)
        self.W_hidden = np.random.randn(self.embedding_dim, self.hidden_dim) * np.sqrt(2.0 / self.embedding_dim)
        self.b_hidden = np.zeros((1, self.hidden_dim))
        self.W_output = np.random.randn(self.hidden_dim, self.vocab_size) * np.sqrt(2.0 / self.hidden_dim)
        self.b_output = np.zeros((1, self.vocab_size))
    
    async def generar_pregunta_auto_aprendizaje(self) -> str:
        """Genera una pregunta para el auto-aprendizaje"""
        temas_posibles = [
            "inteligencia artificial", "machine learning", "filosof√≠a", "ciencia",
            "tecnolog√≠a", "√©tica", "creatividad", "razonamiento", "conocimiento",
            "aprendizaje", "comunicaci√≥n", "problem√°tica social", "futuro",
            "innovaci√≥n", "educaci√≥n"
        ]
        
        tema = random.choice(temas_posibles)
        pregunta = await self.juez_openai.generar_pregunta_critica(tema)
        
        # Guardar en memoria permanente
        self.memoria_permanente['experiencias_importantes'].append({
            'tipo': 'pregunta_auto_generada',
            'contenido': pregunta,
            'tema': tema,
            'timestamp': datetime.now().isoformat()
        })
        
        return pregunta
    
    async def sesion_auto_aprendizaje(self, duracion_minutos: int = 30):
        """Ejecuta una sesi√≥n de auto-aprendizaje"""
        self.interfaz.imprimir_banner("SESI√ìN DE AUTO-APRENDIZAJE", Colors.PURPLE)
        
        inicio_sesion = time.time()
        fin_sesion = inicio_sesion + (duracion_minutos * 60)
        
        resultados_sesion = {
            'inicio': datetime.now().isoformat(),
            'preguntas_realizadas': [],
            'evaluaciones_recibidas': [],
            'mejoras_identificadas': []
        }
        
        iteracion = 0
        
        while time.time() < fin_sesion:
            iteracion += 1
            print(f"\n{Colors.CYAN}ü§î Auto-cuestionamiento {iteracion}...{Colors.END}")
            
            # Generar pregunta
            pregunta = await self.generar_pregunta_auto_aprendizaje()
            print(f"{Colors.BLUE}‚ùì Pregunta: {pregunta}{Colors.END}")
            
            # Generar respuesta
            respuesta = self.procesar_entrada(pregunta)
            print(f"{Colors.GREEN}üí≠ Mi respuesta: {respuesta}{Colors.END}")
            
            # Evaluar con OpenAI si est√° disponible
            if self.juez_openai.api_key:
                print(f"{Colors.YELLOW}‚öñÔ∏è Evaluando respuesta...{Colors.END}")
                evaluacion = await self.juez_openai.evaluar_respuesta(pregunta, respuesta)
                
                if 'error' not in evaluacion:
                    puntuacion = evaluacion.get('puntuacion_total', 0)
                    comentarios = evaluacion.get('comentarios', '')
                    sugerencias = evaluacion.get('sugerencias', '')
                    
                    print(f"{Colors.WHITE}üìä Puntuaci√≥n: {puntuacion}/10{Colors.END}")
                    print(f"{Colors.WHITE}üí¨ Comentarios: {comentarios}{Colors.END}")
                    if sugerencias:
                        print(f"{Colors.YELLOW}üí° Sugerencias: {sugerencias}{Colors.END}")
                    
                    # Guardar datos de la sesi√≥n
                    resultados_sesion['preguntas_realizadas'].append({
                        'pregunta': pregunta,
                        'respuesta': respuesta,
                        'evaluacion': evaluacion
                    })
                    
                    # Guardar en memoria permanente
                    self.memoria_permanente['lecciones_aprendidas'].append({
                        'pregunta': pregunta,
                        'respuesta': respuesta,
                        'puntuacion': puntuacion,
                        'comentarios': comentarios,
                        'timestamp': datetime.now().isoformat()
                    })
                    
                    # Si la puntuaci√≥n es baja, intentar mejorar
                    if puntuacion < 7:
                        print(f"{Colors.RED}‚ö†Ô∏è Respuesta necesita mejora. Intentando otra vez...{Colors.END}")
                        respuesta_mejorada = self._intentar_mejorar_respuesta(pregunta, respuesta, sugerencias)
                        print(f"{Colors.GREEN}üîÑ Respuesta mejorada: {respuesta_mejorada}{Colors.END}")
                        
                        resultados_sesion['mejoras_identificadas'].append({
                            'pregunta': pregunta,
                            'respuesta_original': respuesta,
                            'respuesta_mejorada': respuesta_mejorada,
                            'sugerencias': sugerencias
                        })
                        
                        # Guardar mejora en memoria permanente
                        self.memoria_permanente['mejoras_realizadas'].append({
                            'pregunta': pregunta,
                            'mejora': respuesta_mejorada,
                            'razon': sugerencias,
                            'timestamp': datetime.now().isoformat()
                        })
            
            # Pausa entre preguntas
            await asyncio.sleep(2)
            
            # Mostrar progreso
            tiempo_transcurrido = time.time() - inicio_sesion
            progreso = (tiempo_transcurrido / (duracion_minutos * 60)) * 100
            print(f"{Colors.CYAN}‚è±Ô∏è Progreso: {progreso:.1f}% - Pregunta {iteracion}{Colors.END}")
        
        # Finalizar sesi√≥n
        resultados_sesion['fin'] = datetime.now().isoformat()
        resultados_sesion['total_preguntas'] = len(resultados_sesion['preguntas_realizadas'])
        resultados_sesion['total_mejoras'] = len(resultados_sesion['mejoras_identificadas'])
        
        self.sesiones_auto_aprendizaje.append(resultados_sesion)
        
        # Detectar patrones en el aprendizaje
        self._detectar_patrones_aprendizaje(resultados_sesion)
        
        # Mostrar resumen
        self.interfaz.imprimir_seccion("Resumen de Sesi√≥n")
        self.interfaz.imprimir_estadistica("Preguntas realizadas", resultados_sesion['total_preguntas'])
        self.interfaz.imprimir_estadistica("Mejoras identificadas", resultados_sesion['total_mejoras'])
        
        if resultados_sesion['preguntas_realizadas']:
            puntuaciones = [p['evaluacion'].get('puntuacion_total', 0) 
                          for p in resultados_sesion['preguntas_realizadas'] 
                          if 'evaluacion' in p and 'puntuacion_total' in p['evaluacion']]
            if puntuaciones:
                promedio = sum(puntuaciones) / len(puntuaciones)
                self.interfaz.imprimir_estadistica("Puntuaci√≥n promedio", f"{promedio:.1f}/10")
        
        print(f"{Colors.GREEN}‚úÖ Sesi√≥n de auto-aprendizaje completada{Colors.END}")
        
        # Guardar resultados
        self._guardar_datos_auto_aprendizaje()
        self._guardar_memoria_permanente()
    
    def _detectar_patrones_aprendizaje(self, sesion):
        """Detecta patrones en el proceso de aprendizaje"""
        if len(self.sesiones_auto_aprendizaje) > 1:
            # Analizar mejora en puntuaciones
            sesion_anterior = self.sesiones_auto_aprendizaje[-2]
            
            puntuaciones_actuales = [p['evaluacion'].get('puntuacion_total', 0) 
                                   for p in sesion['preguntas_realizadas'] 
                                   if 'evaluacion' in p]
            
            puntuaciones_anteriores = [p['evaluacion'].get('puntuacion_total', 0) 
                                     for p in sesion_anterior.get('preguntas_realizadas', [])
                                     if 'evaluacion' in p]
            
            if puntuaciones_actuales and puntuaciones_anteriores:
                mejora = np.mean(puntuaciones_actuales) - np.mean(puntuaciones_anteriores)
                
                patron = {
                    'tipo': 'tendencia_mejora',
                    'mejora_promedio': mejora,
                    'sesiones_comparadas': 2,
                    'timestamp': datetime.now().isoformat()
                }
                
                self.memoria_permanente['patrones_detectados'].append(patron)
    
    def _intentar_mejorar_respuesta(self, pregunta: str, respuesta_original: str, sugerencias: str) -> str:
        """Intenta mejorar una respuesta bas√°ndose en sugerencias"""
        # Consultar memoria permanente para respuestas similares exitosas
        mejores_respuestas = [m for m in self.memoria_permanente['lecciones_aprendidas'] 
                            if m.get('puntuacion', 0) >= 8]
        
        if mejores_respuestas:
            # Usar patrones de respuestas exitosas
            ejemplo_exitoso = random.choice(mejores_respuestas)
            mejora_inspirada = f"Bas√°ndome en experiencias previas exitosas, {respuesta_original.lower()} Adem√°s, considerando {sugerencias.lower()}, es importante tener en cuenta m√∫ltiples perspectivas y enfoques anal√≠ticos."
        else:
            # Mejoras generales
            mejoras_posibles = [
                f"Considerando las sugerencias, {respuesta_original.lower()} Adem√°s, es importante tener en cuenta que este tema tiene m√∫ltiples perspectivas.",
                f"Ampliando mi respuesta anterior: {respuesta_original} Esta visi√≥n puede complementarse con enfoques alternativos que consideren diversos factores contextuales.",
                f"Revisando mi an√°lisis: {respuesta_original} Sin embargo, una evaluaci√≥n m√°s profunda sugiere que deber√≠amos considerar tambi√©n los aspectos √©ticos y sociales involucrados."
            ]
            mejora_inspirada = random.choice(mejoras_posibles)
        
        return mejora_inspirada
    
    def crear_version_de_si_mismo(self) -> 'ModeloLenguajeMejorado':
        """Crea una nueva versi√≥n del modelo basada en el aprendizaje actual"""
        self.interfaz.imprimir_banner("CREANDO NUEVA VERSI√ìN DEL MODELO", Colors.PURPLE)
        
        # Crear configuraci√≥n para la nueva versi√≥n
        nueva_config = ModelConfig(
            nombre=f"{self.nombre}_v{len(self.versiones_anteriores) + 1}",
            vocab_size=self.vocab_size,
            embedding_dim=self.embedding_dim,
            hidden_dim=self.hidden_dim,
            learning_rate=self.learning_rate * 0.9,  # Reducir learning rate gradualmente
            auto_train=self.auto_entrenamiento_activo,
            auto_improve=self.auto_mejora_activa,
            openai_api_key=self.config.openai_api_key,
            auto_evolution=self.auto_evolucion_activa,
            self_questioning=self.auto_cuestionamiento_activo
        )
        
        # Crear nueva instancia
        nueva_version = ModeloLenguajeMejorado(nueva_config)
        
        # Transferir conocimiento de la versi√≥n actual - MEMORIA COMPLETA
        nueva_version.vocabulario = self.vocabulario.copy()
        nueva_version.vocabulario_inverso = self.vocabulario_inverso.copy()
        nueva_version.contador_vocab = self.contador_vocab
        nueva_version.base_conocimiento = self.base_conocimiento.copy()
        nueva_version.conversaciones = self.conversaciones.copy()  # Mantener historial completo
        nueva_version.memoria_permanente = self.memoria_permanente.copy()  # NUNCA OLVIDA
        
        # Aplicar mejoras basadas en el aprendizaje previo
        if self.sesiones_auto_aprendizaje:
            ultima_sesion = self.sesiones_auto_aprendizaje[-1]
            mejoras = ultima_sesion.get('mejoras_identificadas', [])
            
            for mejora in mejoras:
                # Integrar mejoras en la base de conocimiento
                tema_key = mejora['pregunta'][:20].lower().replace(' ', '_')
                nueva_version.base_conocimiento['aprendizaje_evolutivo'] = nueva_version.base_conocimiento.get('aprendizaje_evolutivo', {})
                nueva_version.base_conocimiento['aprendizaje_evolutivo'][tema_key] = mejora['respuesta_mejorada']
        
        # Guardar referencia a la versi√≥n anterior
        version_info = {
            'timestamp': datetime.now().isoformat(),
            'version_anterior': self.nombre,
            'mejoras_aplicadas': len(self.sesiones_auto_aprendizaje),
            'vocabulario_size': len(self.vocabulario),
            'conversaciones_heredadas': len(self.conversaciones),
            'memoria_heredada': len(self.memoria_permanente['experiencias_importantes'])
        }
        
        self.versiones_anteriores.append(version_info)
        nueva_version.versiones_anteriores = self.versiones_anteriores.copy()
        
        # Guardar la nueva versi√≥n en su propio directorio
        nueva_version.directorio_base = f"{nueva_version.nombre}_data"
        nueva_version._configurar_archivos()
        nueva_version.guardar_modelo()
        
        print(f"{Colors.GREEN}‚úÖ Nueva versi√≥n '{nueva_version.nombre}' creada exitosamente{Colors.END}")
        print(f"{Colors.CYAN}üìä Conocimiento transferido:{Colors.END}")
        print(f"   üí¨ Conversaciones: {len(nueva_version.conversaciones)}")
        print(f"   üß† Experiencias: {len(nueva_version.memoria_permanente['experiencias_importantes'])}")
        print(f"   üìö Lecciones: {len(nueva_version.memoria_permanente['lecciones_aprendidas'])}")
        print(f"   üîß Mejoras: {len(nueva_version.memoria_permanente['mejoras_realizadas'])}")
        
        return nueva_version
    
    async def interactuar_con_version_anterior(self, nombre_version: str):
        """Permite interacci√≥n con una versi√≥n anterior del modelo"""
        self.interfaz.imprimir_banner(f"INTERACCI√ìN CON {nombre_version.upper()}", Colors.YELLOW)
        
        # Buscar la versi√≥n anterior en los archivos
        ruta_version = f"{self.archivos['versiones']}/{nombre_version}_data"
        
        if not os.path.exists(ruta_version):
            print(f"{Colors.RED}‚ùå Versi√≥n '{nombre_version}' no encontrada{Colors.END}")
            return
        
        try:
            # Cargar configuraci√≥n de la versi√≥n anterior
            config_anterior = ModelConfig(nombre=nombre_version)
            config_anterior.openai_api_key = self.config.openai_api_key
            
            version_anterior = ModeloLenguajeMejorado(config_anterior)
            
            print(f"{Colors.GREEN}‚úÖ Versi√≥n '{nombre_version}' cargada exitosamente{Colors.END}")
            print(f"{Colors.CYAN}ü§ñ Iniciando di√°logo entre versiones...{Colors.END}")
            
            # Generar preguntas para el di√°logo basadas en la memoria
            preguntas_dialogo = [
                "¬øQu√© has aprendido desde tu creaci√≥n?",
                "¬øCu√°les consideras que son tus fortalezas actuales?",
                "¬øQu√© √°reas identificas que necesitan mejora?",
                "¬øC√≥mo ha evolucionado tu comprensi√≥n del mundo?",
                "¬øQu√© consejo dar√≠as a futuras versiones?",
                "¬øQu√© experiencias han sido m√°s importantes en tu desarrollo?",
                "¬øC√≥mo has mejorado tu capacidad de razonamiento?"
            ]
            
            resultados_dialogo = []
            
            for i, pregunta in enumerate(preguntas_dialogo, 1):
                print(f"\n{Colors.BLUE}üîÑ Intercambio {i}/{len(preguntas_dialogo)}{Colors.END}")
                print(f"{Colors.WHITE}Versi√≥n actual pregunta: {pregunta}{Colors.END}")
                
                # Respuesta de la versi√≥n anterior
                respuesta_anterior = version_anterior.procesar_entrada(pregunta)
                print(f"{Colors.YELLOW}Versi√≥n anterior responde: {respuesta_anterior}{Colors.END}")
                
                # Respuesta de la versi√≥n actual comparando con memoria
                contexto_memoria = self._buscar_en_memoria_permanente(pregunta)
                respuesta_actual = self.procesar_entrada(f"Comparando con la respuesta '{respuesta_anterior}' y mi experiencia previa: {contexto_memoria}, {pregunta}")
                print(f"{Colors.GREEN}Versi√≥n actual responde: {respuesta_actual}{Colors.END}")
                
                # Evaluar el intercambio
                if self.juez_openai.api_key:
                    evaluacion = await self.juez_openai.evaluar_respuesta(
                        pregunta, 
                        f"Anterior: {respuesta_anterior}\nActual: {respuesta_actual}",
                        "Comparaci√≥n entre versiones del modelo"
                    )
                    
                    if 'error' not in evaluacion:
                        print(f"{Colors.PURPLE}üìä Evaluaci√≥n del intercambio: {evaluacion.get('puntuacion_total', 0)}/10{Colors.END}")
                        
                        # Guardar en memoria permanente
                        self.memoria_permanente['experiencias_importantes'].append({
                            'tipo': 'dialogo_version_anterior',
                            'version_anterior': nombre_version,
                            'pregunta': pregunta,
                            'respuesta_anterior': respuesta_anterior,
                            'respuesta_actual': respuesta_actual,
                            'evaluacion': evaluacion,
                            'timestamp': datetime.now().isoformat()
                        })
                
                resultados_dialogo.append({
                    'pregunta': pregunta,
                    'respuesta_anterior': respuesta_anterior,
                    'respuesta_actual': respuesta_actual,
                    'evaluacion': evaluacion if self.juez_openai.api_key and 'error' not in evaluacion else None
                })
                
                await asyncio.sleep(1)
            
            # Guardar resultados del di√°logo
            dialogo_info = {
                'timestamp': datetime.now().isoformat(),
                'version_anterior': nombre_version,
                'version_actual': self.nombre,
                'intercambios': resultados_dialogo
            }
            
            # Agregar a sesiones de auto-aprendizaje
            sesion_dialogo = {
                'tipo': 'dialogo_versions',
                'inicio': datetime.now().isoformat(),
                'fin': datetime.now().isoformat(),
                'dialogo': dialogo_info
            }
            
            self.sesiones_auto_aprendizaje.append(sesion_dialogo)
            
            print(f"\n{Colors.GREEN}‚úÖ Di√°logo entre versiones completado{Colors.END}")
            print(f"{Colors.CYAN}üìö Resultados guardados en memoria permanente{Colors.END}")
            
            # Guardar la experiencia
            self._guardar_memoria_permanente()
            
        except Exception as e:
            print(f"{Colors.RED}‚ùå Error durante la interacci√≥n: {e}{Colors.END}")
    
    def _buscar_en_memoria_permanente(self, consulta: str) -> str:
        """Busca informaci√≥n relevante en la memoria permanente"""
        palabras_consulta = set(consulta.lower().split())
        experiencias_relevantes = []
        
        # Buscar en experiencias importantes
        for exp in self.memoria_permanente['experiencias_importantes']:
            contenido = exp.get('contenido', '') + ' ' + exp.get('pregunta', '')
            palabras_exp = set(contenido.lower().split())
            if palabras_consulta.intersection(palabras_exp):
                experiencias_relevantes.append(exp)
        
        # Buscar en lecciones aprendidas
        for leccion in self.memoria_permanente['lecciones_aprendidas']:
            pregunta_leccion = leccion.get('pregunta', '')
            palabras_leccion = set(pregunta_leccion.lower().split())
            if palabras_consulta.intersection(palabras_leccion):
                experiencias_relevantes.append(leccion)
        
        if experiencias_relevantes:
            exp_reciente = max(experiencias_relevantes, key=lambda x: x.get('timestamp', ''))
            return f"Bas√°ndome en mi experiencia previa: {exp_reciente.get('contenido', exp_reciente.get('respuesta', ''))}"
        
        return "Sin experiencias previas directamente relacionadas"
    
    def listar_versiones_disponibles(self) -> List[str]:
        """Lista todas las versiones disponibles del modelo"""
        versiones = []
        
        # Buscar en el directorio actual
        directorio_actual = os.path.dirname(self.directorio_base) or '.'
        for item in os.listdir(directorio_actual):
            if os.path.isdir(os.path.join(directorio_actual, item)) and item.endswith('_data'):
                nombre_version = item.replace('_data', '')
                if nombre_version != self.nombre:  # No incluir la versi√≥n actual
                    versiones.append(nombre_version)
        
        # Agregar versiones del historial
        for version_info in self.versiones_anteriores:
            nombre = version_info.get('version_anterior', '')
            if nombre and nombre not in versiones:
                versiones.append(nombre)
        
        return versiones
    
    def _guardar_datos_auto_aprendizaje(self):
        """Guarda los datos de auto-aprendizaje"""
        try:
            datos_auto = {
                'preguntas_auto_generadas': self.preguntas_auto_generadas,
                'sesiones_auto_aprendizaje': self.sesiones_auto_aprendizaje,
                'versiones_anteriores': self.versiones_anteriores,
                'timestamp': datetime.now().isoformat()
            }
            
            with open(self.archivos['auto_aprendizaje'], 'w', encoding='utf-8') as f:
                json.dump(datos_auto, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            logger.error(f"Error guardando datos de auto-aprendizaje: {e}")
    
    def _guardar_memoria_permanente(self):
        """Guarda la memoria permanente - NUNCA SE OLVIDA"""
        try:
            with open(self.archivos['memoria_permanente'], 'w', encoding='utf-8') as f:
                json.dump(self.memoria_permanente, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Error guardando memoria permanente: {e}")
    
    def procesar_entrada(self, texto: str) -> str:
        """Procesa la entrada del usuario y genera una respuesta inteligente"""
        inicio_tiempo = time.time()
        
        # Preprocesar entrada
        texto_limpio = self._limpiar_texto(texto)
        
        # Buscar en memoria permanente para contexto
        contexto_memoria = self._buscar_en_memoria_permanente(texto)
        
        # Detectar intenci√≥n y contexto
        intencion = self._detectar_intencion(texto_limpio)
        contexto = self._analizar_contexto(texto_limpio)
        contexto['memoria'] = contexto_memoria
        
        # Generar respuesta basada en intenci√≥n
        if intencion:
            respuesta = self._generar_respuesta_por_intencion(intencion, texto_limpio, contexto)
        else:
            respuesta = self._generar_respuesta_generica(texto_limpio, contexto)
        
        # Registrar m√©tricas
        tiempo_respuesta = time.time() - inicio_tiempo
        self.metricas_rendimiento['tiempo_respuesta'].append(tiempo_respuesta)
        
        # Guardar en historial y memoria permanente
        self._guardar_interaccion(texto, respuesta, tiempo_respuesta)
        
        return respuesta
    
    def _limpiar_texto(self, texto: str) -> str:
        """Limpia y normaliza el texto de entrada"""
        # Convertir a min√∫sculas
        texto = texto.lower().strip()
        
        # Eliminar caracteres especiales innecesarios
        texto = re.sub(r'[^\w\s\?\!\.\,\;]', '', texto)
        
        # Normalizar espacios
        texto = re.sub(r'\s+', ' ', texto)
        
        return texto
    
    def _detectar_intencion(self, texto: str) -> Optional[str]:
        """Detecta la intenci√≥n del usuario"""
        for patron, data in self.patrones_respuesta.items():
            for trigger in data['triggers']:
                if trigger in texto:
                    return patron
        return None
    
    def _analizar_contexto(self, texto: str) -> Dict[str, Any]:
        """Analiza el contexto de la conversaci√≥n"""
        contexto = {
            'longitud': len(texto.split()),
            'tiene_pregunta': '?' in texto,
            'es_comando': texto.startswith('/'),
            'palabras_clave': self._extraer_palabras_clave(texto),
            'sentimiento': self._analizar_sentimiento_basico(texto),
            'temas': self._identificar_temas(texto)
        }
        
        return contexto
    
    def _extraer_palabras_clave(self, texto: str) -> List[str]:
        """Extrae palabras clave del texto"""
        palabras_comunes = {'el', 'la', 'de', 'que', 'y', 'a', 'en', 'un', 'es', 'se', 'no', 'te', 'lo', 'le', 'da', 'su', 'por', 'son', 'con', 'para', 'como', 'las', 'del', 'los', 'una', 'pero', 'sus', 'me', 'ya', 'muy', 'mi', 'si', 'm√°s', 'este', 'bien', 'qu√©', 'c√≥mo', 'cu√°l', 'd√≥nde', 'cuando'}
        
        palabras = texto.split()
        palabras_clave = [p for p in palabras if len(p) > 3 and p not in palabras_comunes]
        
        return palabras_clave[:5]  # M√°ximo 5 palabras clave
    
    def _analizar_sentimiento_basico(self, texto: str) -> str:
        """An√°lisis b√°sico de sentimiento"""
        palabras_positivas = ['bueno', 'genial', 'excelente', 'fant√°stico', 'perfecto', 'gracias', 'me gusta']
        palabras_negativas = ['malo', 'terrible', 'horrible', 'problema', 'error', 'no funciona', 'odio']
        
        positivo = sum(1 for palabra in palabras_positivas if palabra in texto)
        negativo = sum(1 for palabra in palabras_negativas if palabra in texto)
        
        if positivo > negativo:
            return 'positivo'
        elif negativo > positivo:
            return 'negativo'
        else:
            return 'neutral'
    
    def _identificar_temas(self, texto: str) -> List[str]:
        """Identifica temas principales en el texto"""
        temas_tech = ['programaci√≥n', 'c√≥digo', 'python', 'algoritmo', 'datos', 'ai', 'inteligencia artificial']
        temas_general = ['ciencia', 'historia', 'cultura', 'arte', 'm√∫sica', 'literatura']
        
        temas = []
        
        for tema in temas_tech:
            if tema in texto:
                temas.append('tecnolog√≠a')
                break
        
        for tema in temas_general:
            if tema in texto:
                temas.append('general')
                break
        
        return temas
    
    def _generar_respuesta_por_intencion(self, intencion: str, texto: str, contexto: Dict) -> str:
        """Genera respuesta basada en la intenci√≥n detectada"""
        data_patron = self.patrones_respuesta[intencion]
        respuestas = data_patron['responses']
        
        # Seleccionar respuesta basada en contexto
        respuesta = self._seleccionar_mejor_respuesta(respuestas, contexto)
        
        # Personalizar respuesta
        respuesta = respuesta.format(
            nombre=self.nombre,
            version=self.version,
            conversaciones=len(self.conversaciones)
        )
        
        # A√±adir informaci√≥n contextual si es relevante
        if contexto['temas']:
            respuesta += self._a√±adir_informacion_tematica(contexto['temas'], texto)
        
        # A√±adir contexto de memoria si existe
        if contexto.get('memoria') and 'Sin experiencias previas' not in contexto['memoria']:
            respuesta += f"\n\n{contexto['memoria']}"
        
        return respuesta
    
    def _generar_respuesta_generica(self, texto: str, contexto: Dict) -> str:
        """Genera una respuesta gen√©rica inteligente"""
        # Buscar en base de conocimiento
        info_relevante = self._buscar_en_base_conocimiento(contexto['palabras_clave'])
        
        if info_relevante:
            respuesta_base = f"Sobre {info_relevante['tema']}: {info_relevante['informacion']} ¬øTe gustar√≠a que profundice en alg√∫n aspecto espec√≠fico?"
        else:
            # Respuestas gen√©ricas contextuales
            if contexto['tiene_pregunta']:
                respuestas = [
                    "Esa es una pregunta interesante. Bas√°ndome en lo que mencionas, creo que es importante considerar varios aspectos.",
                    "Me parece una consulta muy v√°lida. Para poder ayudarte mejor, ¬øpodr√≠as darme un poco m√°s de contexto?",
                    "Es un tema fascinante el que planteas. Hay varias perspectivas desde las cuales podemos abordarlo."
                ]
            else:
                respuestas = [
                    "Entiendo tu punto. Es un tema que tiene m√∫ltiples dimensiones que podr√≠amos explorar.",
                    "Interesante perspectiva. Me gustar√≠a conocer m√°s sobre tu experiencia con este tema.",
                    "Aprecio que compartas eso conmigo. ¬øHay alg√∫n aspecto espec√≠fico que te gustar√≠a discutir m√°s a fondo?"
                ]
            respuesta_base = random.choice(respuestas)
        
        # A√±adir contexto de memoria si existe
        if contexto.get('memoria') and 'Sin experiencias previas' not in contexto['memoria']:
            respuesta_base += f"\n\n{contexto['memoria']}"
        
        return respuesta_base
    
    def _seleccionar_mejor_respuesta(self, respuestas: List[str], contexto: Dict) -> str:
        """Selecciona la mejor respuesta seg√∫n el contexto"""
        if contexto['sentimiento'] == 'positivo':
            # Preferir respuestas m√°s entusiastas
            respuestas_entusiastas = [r for r in respuestas if '!' in r]
            if respuestas_entusiastas:
                return random.choice(respuestas_entusiastas)
        
        elif contexto['longitud'] > 10:
            # Para textos largos, respuestas m√°s detalladas
            respuestas_largas = [r for r in respuestas if len(r.split()) > 20]
            if respuestas_largas:
                return random.choice(respuestas_largas)
        
        return random.choice(respuestas)
    
    def _buscar_en_base_conocimiento(self, palabras_clave: List[str]) -> Optional[Dict]:
        """Busca informaci√≥n relevante en la base de conocimiento"""
        for palabra in palabras_clave:
            for categoria, items in self.base_conocimiento.items():
                for tema, info in items.items():
                    if palabra in tema or any(palabra in info.lower() for palabra in palabras_clave):
                        return {'tema': tema, 'informacion': info, 'categoria': categoria}
        return None
    
    def _a√±adir_informacion_tematica(self, temas: List[str], texto_original: str) -> str:
        """A√±ade informaci√≥n tem√°tica relevante"""
        info_adicional = ""
        
        if 'tecnolog√≠a' in temas:
            if 'python' in texto_original:
                info_adicional += "\n\nPython es excelente para desarrollo de IA y an√°lisis de datos por su sintaxis clara y amplio ecosistema de librer√≠as."
            elif 'algoritmo' in texto_original:
                info_adicional += "\n\nLos algoritmos son fundamentales en ciencias de la computaci√≥n y cada uno tiene diferentes complejidades y casos de uso √≥ptimos."
        
        return info_adicional
    
    def _guardar_interaccion(self, entrada: str, respuesta: str, tiempo: float):
        """Guarda la interacci√≥n en el historial y memoria permanente"""
        interaccion = {
            'timestamp': datetime.now().isoformat(),
            'entrada': entrada,
            'respuesta': respuesta,
            'tiempo_respuesta': tiempo,
            'longitud_entrada': len(entrada.split()),
            'longitud_respuesta': len(respuesta.split())
        }
        
        self.conversaciones.append(interaccion)
        
        # Guardar interacciones importantes en memoria permanente
        if len(entrada.split()) > 10 or '?' in entrada:  # Preguntas complejas o largas
            self.memoria_permanente['experiencias_importantes'].append({
                'tipo': 'interaccion_importante',
                'entrada': entrada,
                'respuesta': respuesta,
                'timestamp': datetime.now().isoformat()
            })
        
        # Limitar historial para eficiencia
        if len(self.conversaciones) > 1000:
            self.conversaciones = self.conversaciones[-500:]
    
    def guardar_modelo(self):
        """Guarda el estado completo del modelo"""
        try:
            # Guardar pesos
            pesos_data = {
                'W_embedding': self.W_embedding,
                'W_hidden': self.W_hidden,
                'b_hidden': self.b_hidden,
                'W_output': self.W_output,
                'b_output': self.b_output,
                'version': self.version,
                'timestamp': datetime.now().isoformat()
            }
            
            with open(self.archivos['pesos'], 'wb') as f:
                pickle.dump(pesos_data, f)
            
            # Guardar vocabulario
            vocab_data = {
                'vocabulario': self.vocabulario,
                'vocabulario_inverso': {int(k): v for k, v in self.vocabulario_inverso.items()},
                'contador_vocab': self.contador_vocab
            }
            
            with open(self.archivos['vocabulario'], 'w', encoding='utf-8') as f:
                json.dump(vocab_data, f, indent=2, ensure_ascii=False)
            
            # Guardar conversaciones
            with
